{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13857621,"sourceType":"datasetVersion","datasetId":8808355},{"sourceId":13858477,"sourceType":"datasetVersion","datasetId":8808735},{"sourceId":13911164,"sourceType":"datasetVersion","datasetId":8863810},{"sourceId":13926825,"sourceType":"datasetVersion","datasetId":8874706}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"L4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/deepinsight/insightface.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:31:19.860179Z","iopub.execute_input":"2025-11-30T04:31:19.860440Z","iopub.status.idle":"2025-11-30T04:31:22.566916Z","shell.execute_reply.started":"2025-11-30T04:31:19.860422Z","shell.execute_reply":"2025-11-30T04:31:22.566061Z"},"id":"xUKdzc2OSAC0","outputId":"29d30189-0b3f-4199-b79a-699a609f005b"},"outputs":[{"name":"stdout","text":"Cloning into 'insightface'...\nremote: Enumerating objects: 12592, done.\u001b[K\nremote: Counting objects: 100% (148/148), done.\u001b[K\nremote: Compressing objects: 100% (59/59), done.\u001b[K\nremote: Total 12592 (delta 104), reused 89 (delta 89), pack-reused 12444 (from 3)\u001b[K\nReceiving objects: 100% (12592/12592), 58.40 MiB | 37.40 MiB/s, done.\nResolving deltas: 100% (6532/6532), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport math\nfrom tqdm import tqdm\nimport numpy as np\nimport itertools\nfrom collections import defaultdict\nimport os\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom insightface.recognition.arcface_torch.backbones.iresnet import iresnet50\nimport sys\nsys.path.append(\"/kaggle/input/scores\")\nfrom torch.cuda.amp import autocast, GradScaler\nimport arc_scores\n\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:33:49.255739Z","iopub.execute_input":"2025-11-30T04:33:49.256192Z","iopub.status.idle":"2025-11-30T04:33:56.785743Z","shell.execute_reply.started":"2025-11-30T04:33:49.256155Z","shell.execute_reply":"2025-11-30T04:33:56.785171Z"},"id":"XdvN17u5SAC1"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"IMAGE_SIZE = 112\nBATCH_SIZE = 256\nNUM_EPOCHS = 25\nFEATURE_DIM = 512\n\nbase_lr_backbone = 0.1\nbase_lr_margin = 0.5\nweight_decay = 5e-4\n\nstep_milestones = [10, 15, 20]\nstep_gamma = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:34:09.561545Z","iopub.execute_input":"2025-11-30T04:34:09.561839Z","iopub.status.idle":"2025-11-30T04:34:09.566120Z","shell.execute_reply.started":"2025-11-30T04:34:09.561815Z","shell.execute_reply":"2025-11-30T04:34:09.565403Z"},"id":"7pheza9GSAC1"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FastImageFolder(Dataset):\n    def __init__(self, root, transform=None, extensions=('.jpg', '.jpeg', '.png', '.bmp')):\n        self.root = Path(root)\n        self.transform = transform\n        self.extensions = extensions\n        \n        # Scan nhanh và cache paths\n        self.samples = []\n        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        \n        print(f\"Scanning {root}...\")\n        for class_name in self.classes:\n            class_dir = self.root / class_name\n            class_idx = self.class_to_idx[class_name]\n            \n            # Dùng glob thay vì os.walk - nhanh hơn\n            for ext in self.extensions:\n                for img_path in class_dir.glob(f'*{ext}'):\n                    self.samples.append((str(img_path), class_idx))\n        \n        print(f\"Found {len(self.samples)} images in {len(self.classes)} classes\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        path, target = self.samples[idx]\n        image = Image.open(path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:34:11.602215Z","iopub.execute_input":"2025-11-30T04:34:11.602524Z","iopub.status.idle":"2025-11-30T04:34:11.609318Z","shell.execute_reply.started":"2025-11-30T04:34:11.602499Z","shell.execute_reply":"2025-11-30T04:34:11.608500Z"},"id":"YwJc9mZwSAC1"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# =============================================================================\n# DATA AUGMENTATION\n# =============================================================================\ntrain_transforms = transforms.Compose([\n    transforms.Resize((112, 112)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((112, 112)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:34:19.783892Z","iopub.execute_input":"2025-11-30T04:34:19.784676Z","iopub.status.idle":"2025-11-30T04:34:19.789658Z","shell.execute_reply.started":"2025-11-30T04:34:19.784646Z","shell.execute_reply":"2025-11-30T04:34:19.788819Z"},"id":"3kKfb5S9SAC1"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# =============================================================================\n# DATASET & DATALOADER\n# =============================================================================\ntrain_folder = '/kaggle/input/train-ds/train'\ntrain_dataset = FastImageFolder(train_folder, transform=train_transforms)\n\ntest_folder = '/kaggle/input/val-ds/val'\ntest_dataset = FastImageFolder(test_folder, transform=test_transforms)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n    persistent_workers=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n    persistent_workers=True\n)\n\nNUM_CLASSES = len(train_dataset.classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpus = torch.cuda.device_count()\n\nprint(\"=\"*60)\nprint(f\"MULTI-GPU TRAINING SETUP\")\nprint(\"=\"*60)\nprint(f\"GPUs available: {n_gpus}\")\nfor i in range(n_gpus):\n    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\nprint(f\"Dataset: {NUM_CLASSES} classes, {len(train_dataset)} images\")\nprint(f\"Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE})\")\nprint(f\"Epochs: {NUM_EPOCHS}\")\nprint(f\"Steps per epoch: {len(train_loader)}\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:37:03.777323Z","iopub.execute_input":"2025-11-30T04:37:03.777908Z","iopub.status.idle":"2025-11-30T04:37:25.784629Z","shell.execute_reply.started":"2025-11-30T04:37:03.777877Z","shell.execute_reply":"2025-11-30T04:37:25.784007Z"},"id":"6e4mIIvASAC1","outputId":"2ecbd737-d291-42ea-8edd-803cc20f606a"},"outputs":[{"name":"stdout","text":"Scanning /kaggle/input/train-ds/train...\nFound 1119807 images in 5115 classes\nScanning /kaggle/input/val-ds/val...\nFound 114964 images in 555 classes\n============================================================\nMULTI-GPU TRAINING SETUP\n============================================================\nGPUs available: 2\n  GPU 0: Tesla T4\n  GPU 1: Tesla T4\nDataset: 5115 classes, 1119807 images\nBatch size: 256 (effective: 256)\nEpochs: 25\nSteps per epoch: 4375\n============================================================\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# =============================================================================\n# ARCFACE MARGIN\n# =============================================================================\nclass ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, s=64.0, m=0.5):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, inputs, labels):\n        cosine = F.linear(\n            F.normalize(inputs, p=2, dim=1),\n            F.normalize(self.weight, p=2, dim=1)\n        )\n        sine = torch.sqrt(torch.clamp(1.0 - torch.pow(cosine, 2), 1e-9, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:36:26.563722Z","iopub.execute_input":"2025-11-30T04:36:26.564024Z","iopub.status.idle":"2025-11-30T04:36:26.571210Z","shell.execute_reply.started":"2025-11-30T04:36:26.563996Z","shell.execute_reply":"2025-11-30T04:36:26.570556Z"},"id":"A51quA_ySAC2"},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# =============================================================================\n# EVALUATION FUNCTIONS\n# =============================================================================\ndef generate_balanced_pairs(labels, max_per_class=None, random_state=42):\n    rng = np.random.RandomState(random_state)\n\n    label2idx = defaultdict(list)\n    for i, lb in enumerate(labels):\n        label2idx[lb].append(i)\n\n    pos_pairs = []\n    for lb, idxs in label2idx.items():\n        if len(idxs) < 2:\n            continue\n\n        idxs = np.array(idxs)\n        if max_per_class and len(idxs) > max_per_class:\n            idxs = rng.choice(idxs, max_per_class, replace=False)\n\n        pos_pairs.extend(list(itertools.combinations(idxs, 2)))\n\n    n_pos = len(pos_pairs)\n    labels_unique = list(label2idx.keys())\n\n    neg_pairs = []\n    class_pairs = list(itertools.combinations(labels_unique, 2))\n\n    for _ in range(n_pos):\n        lb1, lb2 = class_pairs[rng.randint(len(class_pairs))]\n        i = rng.choice(label2idx[lb1])\n        j = rng.choice(label2idx[lb2])\n        neg_pairs.append((i, j))\n\n    pairs = [(i, j, 1) for (i, j) in pos_pairs] + \\\n            [(i, j, 0) for (i, j) in neg_pairs]\n\n    rng.shuffle(pairs)\n    return pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:39:43.749554Z","iopub.execute_input":"2025-11-30T06:39:43.750076Z","iopub.status.idle":"2025-11-30T06:39:43.756769Z","shell.execute_reply.started":"2025-11-30T06:39:43.750053Z","shell.execute_reply":"2025-11-30T06:39:43.756072Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def evaluate(embs, labels, max_per_class=50, n_linspace=1000, epsilon=1e-6, random_state=42):\n    embs = torch.cat(embs).cpu()\n    labels = torch.cat(labels).cpu().numpy()\n\n    pairs = generate_balanced_pairs(labels, max_per_class)\n    pairs = np.array(pairs)\n\n    idx_a = pairs[:, 0].astype(int)\n    idx_b = pairs[:, 1].astype(int)\n    similarity_scores = torch.sum(embs[idx_a] * embs[idx_b], dim=1).numpy()\n\n    targets = pairs[:, 2].astype(int)\n\n    # Best accuracy\n    thresholds = np.linspace(\n        similarity_scores.min() - epsilon,\n        similarity_scores.max() + epsilon,\n        n_linspace\n    )\n    preds = similarity_scores[None, :] >= thresholds[:, None]\n    accs = (preds == targets).mean(axis=1)\n    best_acc = accs.max()\n    best_th = thresholds[accs.argmax()]\n\n    # ROC & TAR\n    roc_auc = arc_scores.compute_roc_auc(similarity_scores, targets)[\"auc\"]\n    tar_far = arc_scores.tar_at_far(similarity_scores, targets)\n\n    return {\n        \"accuracy\": float(best_acc),\n        \"roc_auc\": float(roc_auc),\n        \"tar_far\": float(tar_far),\n        \"threshold\": float(best_th),\n        \"pos_samples\": len(pairs) // 2,\n        \"neg_samples\": len(pairs) // 2\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:39:38.739878Z","iopub.execute_input":"2025-11-30T06:39:38.740822Z","iopub.status.idle":"2025-11-30T06:39:38.747763Z","shell.execute_reply.started":"2025-11-30T06:39:38.740791Z","shell.execute_reply":"2025-11-30T06:39:38.747069Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def step_lr(optimizer, base_lr_backbone, base_lr_margin, epoch,\n            milestones=[10, 15], gamma=0.1):\n    lr_scale = 1.0\n    for milestone in milestones:\n        if epoch >= milestone:\n            lr_scale *= gamma\n\n    lr_backbone = base_lr_backbone * lr_scale\n    lr_margin = base_lr_margin * lr_scale\n\n    optimizer.param_groups[0][\"lr\"] = lr_backbone\n    optimizer.param_groups[1][\"lr\"] = lr_margin\n\n    return lr_backbone, lr_margin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:36:26.594322Z","iopub.execute_input":"2025-11-30T04:36:26.594693Z","iopub.status.idle":"2025-11-30T04:36:26.611616Z","shell.execute_reply.started":"2025-11-30T04:36:26.594675Z","shell.execute_reply":"2025-11-30T04:36:26.610703Z"},"id":"-2ld3atrSAC2"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# =============================================================================\n# EARLY STOPPING\n# =============================================================================\nclass EarlyStopping:\n    def __init__(self, patience=5, epsilon=0.001, save_path=\"best.pt\"):\n        self.patience = patience\n        self.save_path = save_path\n        self.epsilon = epsilon\n        self.best_acc = -1\n        self.counter = 0\n        self.should_stop = False\n\n    def step(self, val_acc, model, margin):\n        if val_acc > self.best_acc + self.epsilon:\n            self.best_acc = val_acc\n            self.counter = 0\n\n            model_to_save = model.module if hasattr(model, 'module') else model\n            margin_to_save = margin.module if hasattr(margin, 'module') else margin\n\n            checkpoint = {\n                'model_state_dict': model.state_dict(),\n                'margin_state_dict': margin.state_dict(),\n                'best_tar_far': self.best_acc\n            }\n            torch.save(checkpoint, self.save_path)\n            print(f\"✓ Saved best model: TAR@FAR={val_acc:.4f}\")\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.should_stop = True\n                print(\"⚠ Early stopping triggered!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:36:26.612635Z","iopub.execute_input":"2025-11-30T04:36:26.612886Z","iopub.status.idle":"2025-11-30T04:36:26.629184Z","shell.execute_reply.started":"2025-11-30T04:36:26.612869Z","shell.execute_reply":"2025-11-30T04:36:26.627681Z"},"id":"Onmxh1XASAC2"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# =============================================================================\n# MODEL & OPTIMIZER\n# =============================================================================\nmodel = iresnet50().to(device)\nmargin = ArcMarginProduct(\n    in_features=FEATURE_DIM,\n    out_features=NUM_CLASSES,\n    s=64.0,\n    m=0.3\n).to(device)\n\nif n_gpus > 1:\n    print(f\"Using DataParallel with {n_gpus} GPUs\")\n    model = nn.DataParallel(model)\n    margin = nn.DataParallel(margin)\n\nmodel = model.to(device)\nmargin = margin.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD([\n    {\"params\": model.parameters(), \"lr\": base_lr_backbone},\n    {\"params\": margin.parameters(), \"lr\": base_lr_margin}\n], momentum=0.9, weight_decay=5e-4)\n\nsteps_per_epoch = len(train_loader)\n\nscaler = GradScaler()","metadata":{"id":"BmCU3CTuUXA6","outputId":"50a1cc06-6578-41fb-fce1-d8ead673fe57","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:36:26.629795Z","iopub.execute_input":"2025-11-30T04:36:26.630040Z","iopub.status.idle":"2025-11-30T04:36:27.478452Z","shell.execute_reply.started":"2025-11-30T04:36:26.630022Z","shell.execute_reply":"2025-11-30T04:36:27.477711Z"}},"outputs":[{"name":"stdout","text":"Using DataParallel with 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/3766875126.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def train():\n    train_losses = []\n    accs = []\n    rocs = []\n    tfs = []\n    \n    early = EarlyStopping(patience=5, epsilon=0.001)\n    \n    print(f\"\\nStarting training...\")\n    print(f\"Total epochs: {NUM_EPOCHS}\")\n    print(f\"Using {n_gpus} GPU(s)\")\n    print(f\"LR schedule: Step decay at {step_milestones}\")\n    print(f\"Batch size: {BATCH_SIZE} (per GPU: {BATCH_SIZE // n_gpus if n_gpus > 1 else BATCH_SIZE})\\n\")\n    \n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        margin.train()\n\n        train_loss = 0\n        \n        # Get initial LR for display\n        lr_backbone, lr_margin = step_lr(\n            optimizer, base_lr_backbone, base_lr_margin,\n            epoch, milestones=step_milestones, gamma=step_gamma\n        )\n        pbar = tqdm(\n            enumerate(train_loader), \n            total=len(train_loader), \n            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {lr_backbone:.6f}]\"\n        )\n\n        for step, (inputs, targets) in pbar:\n            inputs = inputs.to(device, non_blocking=True)\n            targets = targets.to(device, non_blocking=True)\n\n            optimizer.zero_grad()\n\n            # Forward (with mixed precision if enabled)\n            try:\n                # Try mixed precision first\n                from torch.cuda.amp import autocast, GradScaler\n                if not hasattr(train, '_scaler_initialized'):\n                    train._scaler = GradScaler()\n                    train._scaler_initialized = True\n                \n                with autocast():\n                    outputs = model(inputs)\n                    outputs = F.normalize(outputs, p=2, dim=1)\n                    logits = margin(outputs, targets)\n                    loss = criterion(logits, targets)\n                \n                # Backward with mixed precision\n                train._scaler.scale(loss).backward()\n                train._scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n                train._scaler.step(optimizer)\n                train._scaler.update()\n                \n            except:\n                # Fallback to FP32 if mixed precision fails\n                outputs = model(inputs)\n                outputs = F.normalize(outputs, p=2, dim=1)\n                logits = margin(outputs, targets)\n                loss = criterion(logits, targets)\n                \n                # Backward\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n                optimizer.step()\n\n            train_loss += loss.item()\n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n        avg_train_loss = train_loss / len(train_loader)\n\n        # ==================== EVALUATION ====================\n        model.eval()\n        margin.eval()\n\n        embs = []\n        labels_list = []\n\n        with torch.no_grad():\n            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n                inputs = inputs.to(device, non_blocking=True)\n                targets = targets.to(device, non_blocking=True)\n\n                outputs = model(inputs)\n                outputs = F.normalize(outputs, p=2, dim=1)\n\n                embs.append(outputs.cpu())\n                labels_list.append(targets.cpu())\n\n        eval_res = evaluate(embs, labels_list, max_per_class=50, n_linspace=1000)\n        tar_far = eval_res[\"tar_far\"]\n\n        # Append\n        train_losses.append(avg_train_loss)\n        accs.append(eval_res['accuracy'])\n        rocs.append(eval_res['roc_auc'])\n        tfs.append(tar_far)\n\n        # Get current learning rates\n        current_lr_backbone = optimizer.param_groups[0]['lr']\n        current_lr_margin = optimizer.param_groups[1]['lr']\n\n        print(f\"\\n{'='*60}\")\n        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n        print(f\"Learning Rate: Backbone={current_lr_backbone:.6f}, Margin={current_lr_margin:.6f}\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Eval Metrics:\")\n        print(f\"  - Accuracy: {eval_res['accuracy']:.4f}\")\n        print(f\"  - ROC AUC: {eval_res['roc_auc']:.4f}\")\n        print(f\"  - TAR@FAR: {eval_res['tar_far']:.4f}\")\n        print(f\"  - Threshold: {eval_res['threshold']:.4f}\")\n        print(f\"{'='*60}\\n\")\n\n        # Early Stopping (with multi-GPU support)\n        early.step(tar_far, model, margin)\n        \n        # Save checkpoint every 5 epochs (unwrap DataParallel)\n        model_to_save = model.module if hasattr(model, 'module') else model\n        margin_to_save = margin.module if hasattr(margin, 'module') else margin\n        \n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model_to_save.state_dict(),\n            'margin_state_dict': margin_to_save.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_loss': avg_train_loss,\n            'tar_far': tar_far,\n            'n_gpus': n_gpus\n        }, f'checkpoint_epoch_{epoch+1}.pt')\n        print(f\"✓ Saved checkpoint at epoch {epoch+1}\")\n        \n        if early.should_stop:\n            print(\"⚠ Training stopped early.\")\n            break\n\n    print(f\"\\n✓ Training completed! Best TAR@FAR: {early.best_acc:.4f}\")\n\n    return train_losses, accs, rocs, tfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T14:12:39.853767Z","iopub.execute_input":"2025-11-29T14:12:39.854056Z","iopub.status.idle":"2025-11-29T14:12:39.868522Z","shell.execute_reply.started":"2025-11-29T14:12:39.854035Z","shell.execute_reply":"2025-11-29T14:12:39.867788Z"},"id":"ykGwuNTKSAC2"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_losses, accs, rocs, tfs = train()","metadata":{"trusted":true,"id":"oQYymva6SAC2","outputId":"3c156b4a-765b-4349-fc63-61b9b8e2a9c1","execution":{"iopub.status.busy":"2025-11-29T14:12:45.214122Z","iopub.execute_input":"2025-11-29T14:12:45.214859Z","execution_failed":"2025-11-29T18:32:46.074Z"}},"outputs":[{"name":"stdout","text":"\nStarting training...\nTotal epochs: 10\nUsing 2 GPU(s)\nLR schedule: Step decay at [10, 15, 25]\nBatch size: 256 (per GPU: 128)\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/4188600883.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  train._scaler = GradScaler()\n/tmp/ipykernel_47/4188600883.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 1/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:04<00:00,  1.39s/it, loss=10.6098]\nEvaluating: 100%|██████████| 450/450 [05:03<00:00,  1.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 1/10\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 17.3763\nEval Metrics:\n  - Accuracy: 0.9199\n  - ROC AUC: 0.9739\n  - TAR@FAR: 0.5662\n  - Threshold: 0.3203\n============================================================\n\n✓ Saved best model: TAR@FAR=0.5662\n✓ Saved checkpoint at epoch 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/4188600883.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 2/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:40:42<00:00,  1.38s/it, loss=10.0458]\nEvaluating: 100%|██████████| 450/450 [02:47<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 2/10\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 8.8618\nEval Metrics:\n  - Accuracy: 0.9333\n  - ROC AUC: 0.9804\n  - TAR@FAR: 0.6546\n  - Threshold: 0.2955\n============================================================\n\n✓ Saved best model: TAR@FAR=0.6546\n✓ Saved checkpoint at epoch 2\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/4188600883.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 3/10 [LR: 0.100000]:  73%|███████▎  | 3200/4375 [1:13:42<27:07,  1.39s/it, loss=7.5558]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(path):\n    start_epoch = 0\n    resume_path = path\n\n    if os.path.exists(resume_path):\n        print(f\"==> Loading checkpoint from {resume_path}\")\n        checkpoint = torch.load(resume_path, map_location=device, weights_only=False)\n\n        model_to_load = model.module if hasattr(model, 'module') else model\n        margin_to_load = margin.module if hasattr(margin, 'module') else margin\n\n        model_to_load.load_state_dict(checkpoint['model_state_dict'])\n        margin_to_load.load_state_dict(checkpoint['margin_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n        start_epoch = checkpoint['epoch'] + 1\n        print(f\"==> Resuming from epoch {start_epoch}\")\n\n    return start_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T04:36:27.479110Z","iopub.execute_input":"2025-11-30T04:36:27.479358Z","iopub.status.idle":"2025-11-30T04:36:27.484248Z","shell.execute_reply.started":"2025-11-30T04:36:27.479341Z","shell.execute_reply":"2025-11-30T04:36:27.483646Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def train():\n    train_losses = []\n    accs = []\n    rocs = []\n    tfs = []\n    \n    early = EarlyStopping(patience=5, epsilon=0.001)\n    start_epoch = load_checkpoint(\"/kaggle/input/checkpoints/checkpoint_epoch_2.pt\")\n    \n    print(f\"\\nStarting training...\")\n    print(f\"Total epochs: {NUM_EPOCHS}\")\n    print(f\"Using {n_gpus} GPU(s)\")\n    print(f\"LR schedule: Step decay at {step_milestones}\")\n    print(f\"Batch size: {BATCH_SIZE} (per GPU: {BATCH_SIZE // n_gpus if n_gpus > 1 else BATCH_SIZE})\\n\")\n    \n    for epoch in range(start_epoch, NUM_EPOCHS):\n        model.train()\n        margin.train()\n\n        train_loss = 0\n        \n        # Get initial LR for display\n        lr_backbone, lr_margin = step_lr(\n            optimizer, base_lr_backbone, base_lr_margin,\n            epoch, milestones=step_milestones, gamma=step_gamma\n        )\n        pbar = tqdm(\n            enumerate(train_loader), \n            total=len(train_loader), \n            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {lr_backbone:.6f}]\"\n        )\n\n        for step, (inputs, targets) in pbar:\n            inputs = inputs.to(device, non_blocking=True)\n            targets = targets.to(device, non_blocking=True)\n\n            optimizer.zero_grad()\n\n            # Forward (with mixed precision if enabled)\n            try:\n                # Try mixed precision first\n                from torch.cuda.amp import autocast, GradScaler\n                if not hasattr(train, '_scaler_initialized'):\n                    train._scaler = GradScaler()\n                    train._scaler_initialized = True\n                \n                with autocast():\n                    outputs = model(inputs)\n                    outputs = F.normalize(outputs, p=2, dim=1)\n                    logits = margin(outputs, targets)\n                    loss = criterion(logits, targets)\n                \n                # Backward with mixed precision\n                train._scaler.scale(loss).backward()\n                train._scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n                train._scaler.step(optimizer)\n                train._scaler.update()\n                \n            except:\n                # Fallback to FP32 if mixed precision fails\n                outputs = model(inputs)\n                outputs = F.normalize(outputs, p=2, dim=1)\n                logits = margin(outputs, targets)\n                loss = criterion(logits, targets)\n                \n                # Backward\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n                optimizer.step()\n\n            train_loss += loss.item()\n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n        avg_train_loss = train_loss / len(train_loader)\n\n        # ==================== EVALUATION ====================\n        model.eval()\n        margin.eval()\n\n        embs = []\n        labels_list = []\n\n        with torch.no_grad():\n            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n                inputs = inputs.to(device, non_blocking=True)\n                targets = targets.to(device, non_blocking=True)\n\n                outputs = model(inputs)\n                outputs = F.normalize(outputs, p=2, dim=1)\n\n                embs.append(outputs.cpu())\n                labels_list.append(targets.cpu())\n\n        eval_res = evaluate(embs, labels_list, max_per_class=50, n_linspace=1000)\n        tar_far = eval_res[\"tar_far\"]\n\n        # Append\n        train_losses.append(avg_train_loss)\n        accs.append(eval_res['accuracy'])\n        rocs.append(eval_res['roc_auc'])\n        tfs.append(tar_far)\n\n        # Get current learning rates\n        current_lr_backbone = optimizer.param_groups[0]['lr']\n        current_lr_margin = optimizer.param_groups[1]['lr']\n\n        print(f\"\\n{'='*60}\")\n        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n        print(f\"Learning Rate: Backbone={current_lr_backbone:.6f}, Margin={current_lr_margin:.6f}\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Eval Metrics:\")\n        print(f\"  - Accuracy: {eval_res['accuracy']:.4f}\")\n        print(f\"  - ROC AUC: {eval_res['roc_auc']:.4f}\")\n        print(f\"  - TAR@FAR: {eval_res['tar_far']:.4f}\")\n        print(f\"  - Threshold: {eval_res['threshold']:.4f}\")\n        print(f\"{'='*60}\\n\")\n\n        # Early Stopping (with multi-GPU support)\n        early.step(tar_far, model, margin)\n        \n        # Save checkpoint every 5 epochs (unwrap DataParallel)\n        model_to_save = model.module if hasattr(model, 'module') else model\n        margin_to_save = margin.module if hasattr(margin, 'module') else margin\n        \n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model_to_save.state_dict(),\n            'margin_state_dict': margin_to_save.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_loss': avg_train_loss,\n            'tar_far': tar_far,\n            'n_gpus': n_gpus\n        }, f'checkpoint_epoch_{epoch+1}.pt')\n        print(f\"✓ Saved checkpoint at epoch {epoch+1}\")\n        \n        if early.should_stop:\n            print(\"⚠ Training stopped early.\")\n            break\n\n    print(f\"\\n✓ Training completed! Best TAR@FAR: {early.best_acc:.4f}\")\n\n    return train_losses, accs, rocs, tfs\n\ntrain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:40:00.285086Z","iopub.execute_input":"2025-11-30T06:40:00.285782Z","execution_failed":"2025-11-30T16:06:22.052Z"}},"outputs":[{"name":"stdout","text":"==> Loading checkpoint from /kaggle/input/checkpoints/checkpoint_epoch_2.pt\n==> Resuming from epoch 2\n\nStarting training...\nTotal epochs: 25\nUsing 2 GPU(s)\nLR schedule: Step decay at [10, 15, 20]\nBatch size: 256 (per GPU: 128)\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  train._scaler = GradScaler()\n/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 3/25 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:37<00:00,  1.39s/it, loss=9.3661]\nEvaluating: 100%|██████████| 450/450 [02:50<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 3/25\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 7.8022\nEval Metrics:\n  - Accuracy: 0.9320\n  - ROC AUC: 0.9783\n  - TAR@FAR: 0.6743\n  - Threshold: 0.2669\n============================================================\n\n✓ Saved best model: TAR@FAR=0.6743\n✓ Saved checkpoint at epoch 3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 4/25 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:40<00:00,  1.39s/it, loss=7.4795]\nEvaluating: 100%|██████████| 450/450 [02:50<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 4/25\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 7.3660\nEval Metrics:\n  - Accuracy: 0.9397\n  - ROC AUC: 0.9822\n  - TAR@FAR: 0.6933\n  - Threshold: 0.2959\n============================================================\n\n✓ Saved best model: TAR@FAR=0.6933\n✓ Saved checkpoint at epoch 4\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 5/25 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:44<00:00,  1.40s/it, loss=7.7111]\nEvaluating: 100%|██████████| 450/450 [02:50<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 5/25\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 7.1085\nEval Metrics:\n  - Accuracy: 0.9354\n  - ROC AUC: 0.9806\n  - TAR@FAR: 0.6844\n  - Threshold: 0.2904\n============================================================\n\n✓ Saved checkpoint at epoch 5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 6/25 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:45<00:00,  1.40s/it, loss=5.8907]\nEvaluating: 100%|██████████| 450/450 [02:51<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 6/25\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 6.9227\nEval Metrics:\n  - Accuracy: 0.9375\n  - ROC AUC: 0.9812\n  - TAR@FAR: 0.6882\n  - Threshold: 0.2754\n============================================================\n\n✓ Saved checkpoint at epoch 6\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 7/25 [LR: 0.100000]: 100%|██████████| 4375/4375 [1:41:44<00:00,  1.40s/it, loss=6.8666]\nEvaluating: 100%|██████████| 450/450 [02:50<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEpoch 7/25\nLearning Rate: Backbone=0.100000, Margin=0.500000\nTrain Loss: 6.7780\nEval Metrics:\n  - Accuracy: 0.9365\n  - ROC AUC: 0.9794\n  - TAR@FAR: 0.7053\n  - Threshold: 0.2937\n============================================================\n\n✓ Saved best model: TAR@FAR=0.7053\n✓ Saved checkpoint at epoch 7\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/25 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/1386278631.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/insightface/recognition/arcface_torch/backbones/iresnet.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.fp16):\nEpoch 8/25 [LR: 0.100000]:  63%|██████▎   | 2777/4375 [1:04:30<37:10,  1.40s/it, loss=5.8560]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}