{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135d9faf-699e-48db-b75f-7c824993a1dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:20:29.864322Z",
     "iopub.status.busy": "2025-11-30T04:20:29.864090Z",
     "iopub.status.idle": "2025-11-30T04:20:32.316368Z",
     "shell.execute_reply": "2025-11-30T04:20:32.315489Z",
     "shell.execute_reply.started": "2025-11-30T04:20:29.864304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'insightface'...\n",
      "remote: Enumerating objects: 12592, done.\u001b[K\n",
      "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
      "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
      "remote: Total 12592 (delta 104), reused 89 (delta 89), pack-reused 12444 (from 3)\u001b[K\n",
      "Receiving objects: 100% (12592/12592), 58.40 MiB | 40.99 MiB/s, done.\n",
      "Resolving deltas: 100% (6542/6542), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/deepinsight/insightface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a576b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:20:32.317623Z",
     "iopub.status.busy": "2025-11-30T04:20:32.317408Z",
     "iopub.status.idle": "2025-11-30T04:20:39.557326Z",
     "shell.execute_reply": "2025-11-30T04:20:39.556767Z",
     "shell.execute_reply.started": "2025-11-30T04:20:32.317601Z"
    },
    "id": "5a576b15",
    "papermill": {
     "duration": 11.508584,
     "end_time": "2025-11-25T04:35:23.379370",
     "exception": false,
     "start_time": "2025-11-25T04:35:11.870786",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from insightface.recognition.arcface_torch.backbones.mobilefacenet import get_mbf\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/scores\")\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import arc_scores\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016973f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-30T04:20:39.558872Z",
     "iopub.status.busy": "2025-11-30T04:20:39.558472Z",
     "iopub.status.idle": "2025-11-30T04:20:39.641431Z",
     "shell.execute_reply": "2025-11-30T04:20:39.640711Z",
     "shell.execute_reply.started": "2025-11-30T04:20:39.558853Z"
    },
    "id": "016973f6",
    "outputId": "3dc29e49-1581-458d-e03f-5aebd17db306",
    "papermill": {
     "duration": 0.06109,
     "end_time": "2025-11-25T04:35:23.445412",
     "exception": false,
     "start_time": "2025-11-25T04:35:23.384322",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ba4a457-936b-4308-9be6-2fb7a5686402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:19:36.388010Z",
     "iopub.status.busy": "2025-11-30T05:19:36.387740Z",
     "iopub.status.idle": "2025-11-30T05:19:36.392208Z",
     "shell.execute_reply": "2025-11-30T05:19:36.391475Z",
     "shell.execute_reply.started": "2025-11-30T05:19:36.387989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 112\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 10\n",
    "FEATURE_DIM = 512\n",
    "\n",
    "base_lr_backbone = 0.1\n",
    "base_lr_margin = 0.5\n",
    "weight_decay = 5e-4\n",
    "\n",
    "step_milestones = [10, 15]\n",
    "step_gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073e5cf4-1384-4c4f-bdfd-58e25f81b647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:20:51.597719Z",
     "iopub.status.busy": "2025-11-30T04:20:51.597208Z",
     "iopub.status.idle": "2025-11-30T04:20:51.604403Z",
     "shell.execute_reply": "2025-11-30T04:20:51.603596Z",
     "shell.execute_reply.started": "2025-11-30T04:20:51.597694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FastImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None, extensions=('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.extensions = extensions\n",
    "\n",
    "        # Scan nhanh và cache paths\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        print(f\"Scanning {root}...\")\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.root / class_name\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "            for ext in self.extensions:\n",
    "                for img_path in class_dir.glob(f'*{ext}'):\n",
    "                    self.samples.append((str(img_path), class_idx))\n",
    "\n",
    "        print(f\"Found {len(self.samples)} images in {len(self.classes)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba817c8-c9c1-4f3e-a233-e467f674fccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:20:53.771484Z",
     "iopub.status.busy": "2025-11-30T04:20:53.771143Z",
     "iopub.status.idle": "2025-11-30T04:20:53.776991Z",
     "shell.execute_reply": "2025-11-30T04:20:53.776327Z",
     "shell.execute_reply.started": "2025-11-30T04:20:53.771460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ffeb1e0-a838-4503-987d-4736364ab930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:20:54.580351Z",
     "iopub.status.busy": "2025-11-30T05:20:54.579675Z",
     "iopub.status.idle": "2025-11-30T05:21:14.217880Z",
     "shell.execute_reply": "2025-11-30T05:21:14.217103Z",
     "shell.execute_reply.started": "2025-11-30T05:20:54.580326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /kaggle/input/train-ds/train...\n",
      "Found 1119807 images in 5115 classes\n",
      "Scanning /kaggle/input/val-ds/val...\n",
      "Found 114964 images in 555 classes\n",
      "============================================================\n",
      "MULTI-GPU TRAINING SETUP\n",
      "============================================================\n",
      "GPUs available: 2\n",
      "  GPU 0: Tesla T4\n",
      "  GPU 1: Tesla T4\n",
      "Dataset: 5115 classes, 1119807 images\n",
      "Batch size: 256 (effective: 256)\n",
      "Epochs: 10\n",
      "Steps per epoch: 4375\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/kaggle/input/train-ds/train'\n",
    "train_dataset = FastImageFolder(train_folder, transform=train_transforms)\n",
    "\n",
    "test_folder = '/kaggle/input/val-ds/val'\n",
    "test_dataset = FastImageFolder(test_folder, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"MULTI-GPU TRAINING SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPUs available: {n_gpus}\")\n",
    "for i in range(n_gpus):\n",
    "    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "print(f\"Dataset: {NUM_CLASSES} classes, {len(train_dataset)} images\")\n",
    "print(f\"Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE})\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Steps per epoch: {len(train_loader)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fd39c-4e76-4778-8702-99c5fae1be16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:20:41.502740Z",
     "iopub.status.busy": "2025-11-30T05:20:41.502165Z",
     "iopub.status.idle": "2025-11-30T05:20:41.511059Z",
     "shell.execute_reply": "2025-11-30T05:20:41.510051Z",
     "shell.execute_reply.started": "2025-11-30T05:20:41.502714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SubCenterArcFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=64.0, m=0.5, k=3):\n",
    "        super(SubCenterArcFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.k = k  # số sub-centers mỗi class\n",
    "        \n",
    "        # Weight: [num_classes * k, embedding_dim]\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features * k, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        \n",
    "        # Pre-compute trigonometric values\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
    "        weight_norm = F.normalize(self.weight, p=2, dim=1)\n",
    "        \n",
    "        cosine_all = F.linear(embeddings_norm, weight_norm)\n",
    "        \n",
    "        cosine_all = cosine_all.view(batch_size, self.out_features, self.k)\n",
    "        \n",
    "        sine_all = torch.sqrt(torch.clamp(1.0 - cosine_all ** 2, 1e-9, 1.0))\n",
    "        phi_all = cosine_all * self.cos_m - sine_all * self.sin_m\n",
    "        phi_all = torch.where(cosine_all > self.th, phi_all, cosine_all - self.mm)\n",
    "        \n",
    "        one_hot = torch.zeros(batch_size, self.out_features, 1, device=embeddings.device)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1, 1), 1.0)\n",
    "        \n",
    "        cosine_with_margin = one_hot * phi_all + (1.0 - one_hot) * cosine_all\n",
    "        \n",
    "        output, _ = torch.max(cosine_with_margin, dim=2)\n",
    "        \n",
    "        # Scale\n",
    "        output *= self.s\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41bffc00-3ba1-4187-9129-0101234ea882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:22:46.443328Z",
     "iopub.status.busy": "2025-11-30T04:22:46.442747Z",
     "iopub.status.idle": "2025-11-30T04:22:46.449480Z",
     "shell.execute_reply": "2025-11-30T04:22:46.448882Z",
     "shell.execute_reply.started": "2025-11-30T04:22:46.443307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_balanced_pairs(labels, max_per_class=None, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    label2idx = defaultdict(list)\n",
    "    for i, lb in enumerate(labels):\n",
    "        label2idx[lb].append(i)\n",
    "\n",
    "    pos_pairs = []\n",
    "    for lb, idxs in label2idx.items():\n",
    "        if len(idxs) < 2:\n",
    "            continue\n",
    "\n",
    "        idxs = np.array(idxs)\n",
    "        if max_per_class and len(idxs) > max_per_class:\n",
    "            idxs = rng.choice(idxs, max_per_class, replace=False)\n",
    "\n",
    "        pos_pairs.extend(list(itertools.combinations(idxs, 2)))\n",
    "\n",
    "    n_pos = len(pos_pairs)\n",
    "    labels_unique = list(label2idx.keys())\n",
    "\n",
    "    neg_pairs = []\n",
    "    class_pairs = list(itertools.combinations(labels_unique, 2))\n",
    "\n",
    "    for _ in range(n_pos):\n",
    "        lb1, lb2 = class_pairs[rng.randint(len(class_pairs))]\n",
    "        i = rng.choice(label2idx[lb1])\n",
    "        j = rng.choice(label2idx[lb2])\n",
    "        neg_pairs.append((i, j))\n",
    "\n",
    "    pairs = [(i, j, 1) for (i, j) in pos_pairs] + \\\n",
    "            [(i, j, 0) for (i, j) in neg_pairs]\n",
    "\n",
    "    rng.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831d6ae9-f08d-48ec-b0d0-519a0762032d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:18:23.829519Z",
     "iopub.status.busy": "2025-11-30T05:18:23.828928Z",
     "iopub.status.idle": "2025-11-30T05:18:23.836082Z",
     "shell.execute_reply": "2025-11-30T05:18:23.835380Z",
     "shell.execute_reply.started": "2025-11-30T05:18:23.829492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(embs, labels, max_per_class=50, n_linspace=1000, epsilon=1e-6, random_state=42):\n",
    "    embs = torch.cat(embs).cpu()\n",
    "    labels = torch.cat(labels).cpu().numpy()\n",
    "\n",
    "    pairs = generate_balanced_pairs(labels, max_per_class)\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    idx_a = pairs[:, 0].astype(int)\n",
    "    idx_b = pairs[:, 1].astype(int)\n",
    "    similarity_scores = torch.sum(embs[idx_a] * embs[idx_b], dim=1).numpy()\n",
    "\n",
    "    targets = pairs[:, 2].astype(int)\n",
    "\n",
    "    # Best accuracy\n",
    "    thresholds = np.linspace(\n",
    "        similarity_scores.min() - epsilon,\n",
    "        similarity_scores.max() + epsilon,\n",
    "        n_linspace\n",
    "    )\n",
    "    preds = similarity_scores[None, :] >= thresholds[:, None]\n",
    "    accs = (preds == targets).mean(axis=1)\n",
    "    best_acc = accs.max()\n",
    "    best_th = thresholds[accs.argmax()]\n",
    "\n",
    "    # ROC & TAR\n",
    "    roc_auc = arc_scores.compute_roc_auc(similarity_scores, targets)[\"auc\"]\n",
    "    tar_far1 = arc_scores.tar_at_far(similarity_scores, targets)\n",
    "    tar_far2 = arc_scores.tar_at_far(similarity_scores, targets, 1e-4)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(best_acc),\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"tar_far1\": float(tar_far1),\n",
    "        \"tar_far2\": float(tar_far2),\n",
    "        \"threshold\": float(best_th),\n",
    "        \"pos_samples\": len(pairs) // 2,\n",
    "        \"neg_samples\": len(pairs) // 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f10bac8-a892-4898-bf31-e29a566597dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:22:50.283174Z",
     "iopub.status.busy": "2025-11-30T04:22:50.282938Z",
     "iopub.status.idle": "2025-11-30T04:22:50.287987Z",
     "shell.execute_reply": "2025-11-30T04:22:50.287143Z",
     "shell.execute_reply.started": "2025-11-30T04:22:50.283157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def step_lr(optimizer, base_lr_backbone, base_lr_margin, epoch,\n",
    "            milestones=[10, 15], gamma=0.1):\n",
    "    lr_scale = 1.0\n",
    "    for milestone in milestones:\n",
    "        if epoch >= milestone:\n",
    "            lr_scale *= gamma\n",
    "\n",
    "    lr_backbone = base_lr_backbone * lr_scale\n",
    "    lr_margin = base_lr_margin * lr_scale\n",
    "\n",
    "    optimizer.param_groups[0][\"lr\"] = lr_backbone\n",
    "    optimizer.param_groups[1][\"lr\"] = lr_margin\n",
    "\n",
    "    return lr_backbone, lr_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26891adf-4c5c-4f8e-abc7-8ffbcaad4f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:22:51.927782Z",
     "iopub.status.busy": "2025-11-30T04:22:51.927298Z",
     "iopub.status.idle": "2025-11-30T04:22:51.933586Z",
     "shell.execute_reply": "2025-11-30T04:22:51.932949Z",
     "shell.execute_reply.started": "2025-11-30T04:22:51.927757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EARLY STOPPING\n",
    "# =============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, epsilon=0.001, save_path=\"best.pt\"):\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.epsilon = epsilon\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, val_acc, model, margin):\n",
    "        if val_acc > self.best_acc + self.epsilon:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            margin_to_save = margin.module if hasattr(margin, 'module') else margin\n",
    "\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'margin_state_dict': margin.state_dict(),\n",
    "                'best_tar_far': self.best_acc\n",
    "            }\n",
    "            torch.save(checkpoint, self.save_path)\n",
    "            print(f\"✓ Saved best model: TAR@FAR={val_acc:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "                print(\"⚠ Early stopping triggered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe663d3f-207c-4463-b0c9-839ad9523cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:21:25.547215Z",
     "iopub.status.busy": "2025-11-30T05:21:25.546696Z",
     "iopub.status.idle": "2025-11-30T05:21:25.680011Z",
     "shell.execute_reply": "2025-11-30T05:21:25.679174Z",
     "shell.execute_reply.started": "2025-11-30T05:21:25.547190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataParallel with 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/2374521324.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL & OPTIMIZER\n",
    "# =============================================================================\n",
    "model = get_mbf(fp16=False, num_features=512).to(device)\n",
    "margin = SubCenterArcFace(\n",
    "    in_features=FEATURE_DIM,\n",
    "    out_features=NUM_CLASSES,\n",
    "    s=64.0,\n",
    "    m=0.4\n",
    ").to(device)\n",
    "\n",
    "if n_gpus > 1:\n",
    "    print(f\"Using DataParallel with {n_gpus} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "    margin = nn.DataParallel(margin)\n",
    "\n",
    "model = model.to(device)\n",
    "margin = margin.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([\n",
    "    {\"params\": model.parameters(), \"lr\": base_lr_backbone},\n",
    "    {\"params\": margin.parameters(), \"lr\": base_lr_margin}\n",
    "], momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bb8034e-eccc-4cbd-a3e7-b5f0dff294a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:21:14.219528Z",
     "iopub.status.busy": "2025-11-30T05:21:14.219248Z",
     "iopub.status.idle": "2025-11-30T05:21:14.232923Z",
     "shell.execute_reply": "2025-11-30T05:21:14.232253Z",
     "shell.execute_reply.started": "2025-11-30T05:21:14.219511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_losses = []\n",
    "    accs = []\n",
    "    rocs = []\n",
    "    tfs = []\n",
    "    \n",
    "    early = EarlyStopping(patience=5, epsilon=0.001)\n",
    "    \n",
    "    print(f\"\\nStarting training...\")\n",
    "    print(f\"Total epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"Using {n_gpus} GPU(s)\")\n",
    "    print(f\"LR schedule: Step decay at {step_milestones}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE} (per GPU: {BATCH_SIZE // n_gpus if n_gpus > 1 else BATCH_SIZE})\\n\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        margin.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Get initial LR for display\n",
    "        lr_backbone, lr_margin = step_lr(\n",
    "            optimizer, base_lr_backbone, base_lr_margin,\n",
    "            epoch, milestones=step_milestones, gamma=step_gamma\n",
    "        )\n",
    "        pbar = tqdm(\n",
    "            enumerate(train_loader), \n",
    "            total=len(train_loader), \n",
    "            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {lr_backbone:.6f}]\"\n",
    "        )\n",
    "\n",
    "        for step, (inputs, targets) in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward (with mixed precision if enabled)\n",
    "            try:\n",
    "                # Try mixed precision first\n",
    "                from torch.cuda.amp import autocast, GradScaler\n",
    "                if not hasattr(train, '_scaler_initialized'):\n",
    "                    train._scaler = GradScaler()\n",
    "                    train._scaler_initialized = True\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                    logits = margin(outputs, targets)\n",
    "                    loss = criterion(logits, targets)\n",
    "                \n",
    "                # Backward with mixed precision\n",
    "                train._scaler.scale(loss).backward()\n",
    "                train._scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n",
    "                train._scaler.step(optimizer)\n",
    "                train._scaler.update()\n",
    "                \n",
    "            except:\n",
    "                # Fallback to FP32 if mixed precision fails\n",
    "                outputs = model(inputs)\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                logits = margin(outputs, targets)\n",
    "                loss = criterion(logits, targets)\n",
    "                \n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # ==================== EVALUATION ====================\n",
    "        model.eval()\n",
    "        margin.eval()\n",
    "\n",
    "        embs = []\n",
    "        labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "\n",
    "                embs.append(outputs.cpu())\n",
    "                labels_list.append(targets.cpu())\n",
    "\n",
    "        eval_res = evaluate(embs, labels_list, max_per_class=50, n_linspace=1000)\n",
    "        tar_far1 = eval_res[\"tar_far1\"]\n",
    "        tar_far2 = eval_res[\"tar_far2\"]\n",
    "\n",
    "        # Append\n",
    "        train_losses.append(avg_train_loss)\n",
    "        accs.append(eval_res['accuracy'])\n",
    "        rocs.append(eval_res['roc_auc'])\n",
    "        tfs.append(tar_far1)\n",
    "\n",
    "        # Get current learning rates\n",
    "        current_lr_backbone = optimizer.param_groups[0]['lr']\n",
    "        current_lr_margin = optimizer.param_groups[1]['lr']\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Learning Rate: Backbone={current_lr_backbone:.6f}, Margin={current_lr_margin:.6f}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Eval Metrics:\")\n",
    "        print(f\"  - Accuracy: {eval_res['accuracy']:.4f}\")\n",
    "        print(f\"  - ROC AUC: {eval_res['roc_auc']:.4f}\")\n",
    "        print(f\"  - TAR@FAR1e-3: {eval_res['tar_far1']:.4f}\")\n",
    "        print(f\"  - TAR@FAR1e-4: {eval_res['tar_far2']:.4f}\")\n",
    "        print(f\"  - Threshold: {eval_res['threshold']:.4f}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        # Early Stopping (with multi-GPU support)\n",
    "        early.step(tar_far1, model, margin)\n",
    "        \n",
    "        # Save checkpoint every 5 epochs (unwrap DataParallel)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        margin_to_save = margin.module if hasattr(margin, 'module') else margin\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'margin_state_dict': margin_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'tar_far1e-3': tar_far1,\n",
    "            'tar_far1e-4': tar_far2,\n",
    "            'n_gpus': n_gpus\n",
    "        }, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "        print(f\"✓ Saved checkpoint at epoch {epoch+1}\")\n",
    "        \n",
    "        if early.should_stop:\n",
    "            print(\"⚠ Training stopped early.\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n✓ Training completed! Best TAR@FAR: {early.best_acc:.4f}\")\n",
    "\n",
    "    return train_losses, accs, rocs, tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc08d4-55bc-4077-a837-29c637c3f97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T05:21:29.014881Z",
     "iopub.status.busy": "2025-11-30T05:21:29.014300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Total epochs: 10\n",
      "Using 2 GPU(s)\n",
      "LR schedule: Step decay at [10, 15]\n",
      "Batch size: 256 (per GPU: 128)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/549988159.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  train._scaler = GradScaler()\n",
      "/tmp/ipykernel_47/549988159.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 1/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [32:21<00:00,  2.25it/s, loss=25.7584]\n",
      "Evaluating: 100%|██████████| 450/450 [01:35<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 1/10\n",
      "Learning Rate: Backbone=0.100000, Margin=0.500000\n",
      "Train Loss: 33.0764\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8480\n",
      "  - ROC AUC: 0.9257\n",
      "  - TAR@FAR1e-3: 0.2815\n",
      "  - TAR@FAR1e-4: 0.1374\n",
      "  - Threshold: 0.2334\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.2815\n",
      "✓ Saved checkpoint at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/549988159.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 2/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [32:04<00:00,  2.27it/s, loss=21.0081]\n",
      "Evaluating: 100%|██████████| 450/450 [01:57<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 2/10\n",
      "Learning Rate: Backbone=0.100000, Margin=0.500000\n",
      "Train Loss: 20.7793\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8966\n",
      "  - ROC AUC: 0.9599\n",
      "  - TAR@FAR1e-3: 0.4928\n",
      "  - TAR@FAR1e-4: 0.3206\n",
      "  - Threshold: 0.2648\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.4928\n",
      "✓ Saved checkpoint at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/549988159.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 3/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [33:13<00:00,  2.20it/s, loss=18.7790]\n",
      "Evaluating: 100%|██████████| 450/450 [02:01<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 3/10\n",
      "Learning Rate: Backbone=0.100000, Margin=0.500000\n",
      "Train Loss: 17.1094\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9184\n",
      "  - ROC AUC: 0.9730\n",
      "  - TAR@FAR1e-3: 0.5878\n",
      "  - TAR@FAR1e-4: 0.4338\n",
      "  - Threshold: 0.2528\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.5878\n",
      "✓ Saved checkpoint at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/549988159.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 4/10 [LR: 0.100000]: 100%|██████████| 4375/4375 [32:01<00:00,  2.28it/s, loss=14.8700]\n",
      "Evaluating: 100%|██████████| 450/450 [01:57<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 4/10\n",
      "Learning Rate: Backbone=0.100000, Margin=0.500000\n",
      "Train Loss: 15.7828\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9221\n",
      "  - ROC AUC: 0.9747\n",
      "  - TAR@FAR1e-3: 0.5976\n",
      "  - TAR@FAR1e-4: 0.4025\n",
      "  - Threshold: 0.2479\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.5976\n",
      "✓ Saved checkpoint at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [LR: 0.100000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_47/549988159.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 5/10 [LR: 0.100000]:  76%|███████▋  | 3341/4375 [24:37<07:30,  2.29it/s, loss=15.1815]"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c226-b30b-4777-8d8f-09406229b801",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 442595,
     "sourceId": 1003630,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8770864,
     "sourceId": 13779592,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8827871,
     "sourceId": 13857610,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808355,
     "sourceId": 13857621,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808735,
     "sourceId": 13858477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867027,
     "sourceId": 13915972,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867060,
     "sourceId": 13916389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867030,
     "sourceId": 13916391,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8868944,
     "sourceId": 13920400,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8872641,
     "sourceId": 13923640,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24747.124394,
   "end_time": "2025-11-25T11:27:30.116533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T04:35:02.992139",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
