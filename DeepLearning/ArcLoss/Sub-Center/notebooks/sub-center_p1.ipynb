{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ac21fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:12.662401Z",
     "iopub.status.busy": "2025-11-30T18:35:12.661860Z",
     "iopub.status.idle": "2025-11-30T18:35:15.097308Z",
     "shell.execute_reply": "2025-11-30T18:35:15.096420Z"
    },
    "papermill": {
     "duration": 2.441878,
     "end_time": "2025-11-30T18:35:15.098937",
     "exception": false,
     "start_time": "2025-11-30T18:35:12.657059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'insightface'...\r\n",
      "remote: Enumerating objects: 12592, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (148/148), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (59/59), done.\u001b[K\r\n",
      "remote: Total 12592 (delta 104), reused 89 (delta 89), pack-reused 12444 (from 3)\u001b[K\r\n",
      "Receiving objects: 100% (12592/12592), 58.40 MiB | 41.79 MiB/s, done.\r\n",
      "Resolving deltas: 100% (6542/6542), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/deepinsight/insightface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d00c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:15.108589Z",
     "iopub.status.busy": "2025-11-30T18:35:15.108367Z",
     "iopub.status.idle": "2025-11-30T18:35:24.073046Z",
     "shell.execute_reply": "2025-11-30T18:35:24.072228Z"
    },
    "id": "5a576b15",
    "papermill": {
     "duration": 8.971124,
     "end_time": "2025-11-30T18:35:24.074553",
     "exception": false,
     "start_time": "2025-11-30T18:35:15.103429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from insightface.recognition.arcface_torch.backbones.mobilefacenet import get_mbf\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/scores\")\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import arc_scores\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2a429e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:24.090212Z",
     "iopub.status.busy": "2025-11-30T18:35:24.089713Z",
     "iopub.status.idle": "2025-11-30T18:35:24.177931Z",
     "shell.execute_reply": "2025-11-30T18:35:24.177203Z"
    },
    "id": "016973f6",
    "outputId": "3dc29e49-1581-458d-e03f-5aebd17db306",
    "papermill": {
     "duration": 0.097432,
     "end_time": "2025-11-30T18:35:24.178973",
     "exception": false,
     "start_time": "2025-11-30T18:35:24.081541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45aea50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:24.188447Z",
     "iopub.status.busy": "2025-11-30T18:35:24.187869Z",
     "iopub.status.idle": "2025-11-30T18:35:24.191586Z",
     "shell.execute_reply": "2025-11-30T18:35:24.191025Z"
    },
    "papermill": {
     "duration": 0.009356,
     "end_time": "2025-11-30T18:35:24.192559",
     "exception": false,
     "start_time": "2025-11-30T18:35:24.183203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 112\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 25\n",
    "FEATURE_DIM = 512\n",
    "\n",
    "base_lr_backbone = 0.1\n",
    "base_lr_margin = 0.5\n",
    "weight_decay = 5e-4\n",
    "\n",
    "step_milestones = [5, 13, 19]\n",
    "step_gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21952388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:24.201384Z",
     "iopub.status.busy": "2025-11-30T18:35:24.201182Z",
     "iopub.status.idle": "2025-11-30T18:35:24.207375Z",
     "shell.execute_reply": "2025-11-30T18:35:24.206676Z"
    },
    "papermill": {
     "duration": 0.012017,
     "end_time": "2025-11-30T18:35:24.208484",
     "exception": false,
     "start_time": "2025-11-30T18:35:24.196467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FastImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None, extensions=('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.extensions = extensions\n",
    "\n",
    "        # Scan nhanh và cache paths\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        print(f\"Scanning {root}...\")\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.root / class_name\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "            for ext in self.extensions:\n",
    "                for img_path in class_dir.glob(f'*{ext}'):\n",
    "                    self.samples.append((str(img_path), class_idx))\n",
    "\n",
    "        print(f\"Found {len(self.samples)} images in {len(self.classes)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d21fc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:24.216947Z",
     "iopub.status.busy": "2025-11-30T18:35:24.216748Z",
     "iopub.status.idle": "2025-11-30T18:35:24.221238Z",
     "shell.execute_reply": "2025-11-30T18:35:24.220554Z"
    },
    "papermill": {
     "duration": 0.009964,
     "end_time": "2025-11-30T18:35:24.222304",
     "exception": false,
     "start_time": "2025-11-30T18:35:24.212340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e68914b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:35:24.232013Z",
     "iopub.status.busy": "2025-11-30T18:35:24.231674Z",
     "iopub.status.idle": "2025-11-30T18:36:40.772620Z",
     "shell.execute_reply": "2025-11-30T18:36:40.771792Z"
    },
    "papermill": {
     "duration": 76.546653,
     "end_time": "2025-11-30T18:36:40.773723",
     "exception": false,
     "start_time": "2025-11-30T18:35:24.227070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /kaggle/input/train-ds/train...\n",
      "Found 1119807 images in 5115 classes\n",
      "Scanning /kaggle/input/val-ds/val...\n",
      "Found 114964 images in 555 classes\n",
      "============================================================\n",
      "MULTI-GPU TRAINING SETUP\n",
      "============================================================\n",
      "GPUs available: 2\n",
      "  GPU 0: Tesla T4\n",
      "  GPU 1: Tesla T4\n",
      "Dataset: 5115 classes, 1119807 images\n",
      "Batch size: 256 (effective: 256)\n",
      "Epochs: 25\n",
      "Steps per epoch: 4375\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/kaggle/input/train-ds/train'\n",
    "train_dataset = FastImageFolder(train_folder, transform=train_transforms)\n",
    "\n",
    "test_folder = '/kaggle/input/val-ds/val'\n",
    "test_dataset = FastImageFolder(test_folder, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"MULTI-GPU TRAINING SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPUs available: {n_gpus}\")\n",
    "for i in range(n_gpus):\n",
    "    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "print(f\"Dataset: {NUM_CLASSES} classes, {len(train_dataset)} images\")\n",
    "print(f\"Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE})\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Steps per epoch: {len(train_loader)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e480c45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.783057Z",
     "iopub.status.busy": "2025-11-30T18:36:40.782854Z",
     "iopub.status.idle": "2025-11-30T18:36:40.790240Z",
     "shell.execute_reply": "2025-11-30T18:36:40.789528Z"
    },
    "papermill": {
     "duration": 0.01325,
     "end_time": "2025-11-30T18:36:40.791334",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.778084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SubCenterArcFace(nn.Module):\n",
    "    \"\"\"\n",
    "    Sub-Center ArcFace Loss (CVPR 2020)\n",
    "    Paper: https://arxiv.org/abs/2005.10671\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=64.0, m=0.5, k=3):\n",
    "        super(SubCenterArcFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.k = k  # số sub-centers mỗi class\n",
    "        \n",
    "        # Weight: [num_classes * k, embedding_dim]\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features * k, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        \n",
    "        # Pre-compute trigonometric values\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
    "        weight_norm = F.normalize(self.weight, p=2, dim=1)\n",
    "        \n",
    "        cosine_all = F.linear(embeddings_norm, weight_norm)\n",
    "        \n",
    "        cosine_all = cosine_all.view(batch_size, self.out_features, self.k)\n",
    "        \n",
    "        sine_all = torch.sqrt(torch.clamp(1.0 - cosine_all ** 2, 1e-9, 1.0))\n",
    "        phi_all = cosine_all * self.cos_m - sine_all * self.sin_m\n",
    "        phi_all = torch.where(cosine_all > self.th, phi_all, cosine_all - self.mm)\n",
    "        \n",
    "        one_hot = torch.zeros(batch_size, self.out_features, 1, device=embeddings.device)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1, 1), 1.0)\n",
    "        \n",
    "        cosine_with_margin = one_hot * phi_all + (1.0 - one_hot) * cosine_all\n",
    "        \n",
    "        output, _ = torch.max(cosine_with_margin, dim=2)\n",
    "        \n",
    "        # Scale\n",
    "        output *= self.s\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32006cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.800192Z",
     "iopub.status.busy": "2025-11-30T18:36:40.799970Z",
     "iopub.status.idle": "2025-11-30T18:36:40.805725Z",
     "shell.execute_reply": "2025-11-30T18:36:40.805199Z"
    },
    "papermill": {
     "duration": 0.011339,
     "end_time": "2025-11-30T18:36:40.806697",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.795358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_balanced_pairs(labels, max_per_class=None, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    label2idx = defaultdict(list)\n",
    "    for i, lb in enumerate(labels):\n",
    "        label2idx[lb].append(i)\n",
    "\n",
    "    pos_pairs = []\n",
    "    for lb, idxs in label2idx.items():\n",
    "        if len(idxs) < 2:\n",
    "            continue\n",
    "\n",
    "        idxs = np.array(idxs)\n",
    "        if max_per_class and len(idxs) > max_per_class:\n",
    "            idxs = rng.choice(idxs, max_per_class, replace=False)\n",
    "\n",
    "        pos_pairs.extend(list(itertools.combinations(idxs, 2)))\n",
    "\n",
    "    n_pos = len(pos_pairs)\n",
    "    labels_unique = list(label2idx.keys())\n",
    "\n",
    "    neg_pairs = []\n",
    "    class_pairs = list(itertools.combinations(labels_unique, 2))\n",
    "\n",
    "    for _ in range(n_pos):\n",
    "        lb1, lb2 = class_pairs[rng.randint(len(class_pairs))]\n",
    "        i = rng.choice(label2idx[lb1])\n",
    "        j = rng.choice(label2idx[lb2])\n",
    "        neg_pairs.append((i, j))\n",
    "\n",
    "    pairs = [(i, j, 1) for (i, j) in pos_pairs] + \\\n",
    "            [(i, j, 0) for (i, j) in neg_pairs]\n",
    "\n",
    "    rng.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0baa867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.815481Z",
     "iopub.status.busy": "2025-11-30T18:36:40.815289Z",
     "iopub.status.idle": "2025-11-30T18:36:40.821082Z",
     "shell.execute_reply": "2025-11-30T18:36:40.820493Z"
    },
    "papermill": {
     "duration": 0.011451,
     "end_time": "2025-11-30T18:36:40.822150",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.810699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(embs, labels, max_per_class=50, n_linspace=1000, epsilon=1e-6, random_state=42):\n",
    "    embs = torch.cat(embs).cpu()\n",
    "    labels = torch.cat(labels).cpu().numpy()\n",
    "\n",
    "    pairs = generate_balanced_pairs(labels, max_per_class)\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    idx_a = pairs[:, 0].astype(int)\n",
    "    idx_b = pairs[:, 1].astype(int)\n",
    "    similarity_scores = torch.sum(embs[idx_a] * embs[idx_b], dim=1).numpy()\n",
    "\n",
    "    targets = pairs[:, 2].astype(int)\n",
    "\n",
    "    # Best accuracy\n",
    "    thresholds = np.linspace(\n",
    "        similarity_scores.min() - epsilon,\n",
    "        similarity_scores.max() + epsilon,\n",
    "        n_linspace\n",
    "    )\n",
    "    preds = similarity_scores[None, :] >= thresholds[:, None]\n",
    "    accs = (preds == targets).mean(axis=1)\n",
    "    best_acc = accs.max()\n",
    "    best_th = thresholds[accs.argmax()]\n",
    "\n",
    "    # ROC & TAR\n",
    "    roc_auc = arc_scores.compute_roc_auc(similarity_scores, targets)[\"auc\"]\n",
    "    tar_far1 = arc_scores.tar_at_far(similarity_scores, targets)\n",
    "    tar_far2 = arc_scores.tar_at_far(similarity_scores, targets, 1e-4)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(best_acc),\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"tar_far1\": float(tar_far1),\n",
    "        \"tar_far2\": float(tar_far2),\n",
    "        \"threshold\": float(best_th),\n",
    "        \"pos_samples\": len(pairs) // 2,\n",
    "        \"neg_samples\": len(pairs) // 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e95760f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.830874Z",
     "iopub.status.busy": "2025-11-30T18:36:40.830690Z",
     "iopub.status.idle": "2025-11-30T18:36:40.834374Z",
     "shell.execute_reply": "2025-11-30T18:36:40.833889Z"
    },
    "papermill": {
     "duration": 0.009177,
     "end_time": "2025-11-30T18:36:40.835406",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.826229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step_lr(optimizer, base_lr_backbone, base_lr_margin, epoch,\n",
    "            milestones=[10, 15], gamma=0.1):\n",
    "    lr_scale = 1.0\n",
    "    for milestone in milestones:\n",
    "        if epoch >= milestone:\n",
    "            lr_scale *= gamma\n",
    "\n",
    "    lr_backbone = base_lr_backbone * lr_scale\n",
    "    lr_margin = base_lr_margin * lr_scale\n",
    "\n",
    "    optimizer.param_groups[0][\"lr\"] = lr_backbone\n",
    "    optimizer.param_groups[1][\"lr\"] = lr_margin\n",
    "\n",
    "    return lr_backbone, lr_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6abfcfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.844252Z",
     "iopub.status.busy": "2025-11-30T18:36:40.844049Z",
     "iopub.status.idle": "2025-11-30T18:36:40.848996Z",
     "shell.execute_reply": "2025-11-30T18:36:40.848505Z"
    },
    "papermill": {
     "duration": 0.010579,
     "end_time": "2025-11-30T18:36:40.849900",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.839321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EARLY STOPPING\n",
    "# =============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, epsilon=0.001, save_path=\"best.pt\"):\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.epsilon = epsilon\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, val_acc, model, margin):\n",
    "        if val_acc > self.best_acc + self.epsilon:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            margin_to_save = margin.module if hasattr(margin, 'module') else margin\n",
    "\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'margin_state_dict': margin.state_dict(),\n",
    "                'best_tar_far': self.best_acc\n",
    "            }\n",
    "            torch.save(checkpoint, self.save_path)\n",
    "            print(f\"✓ Saved best model: TAR@FAR={val_acc:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "                print(\"⚠ Early stopping triggered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd36e948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:40.858546Z",
     "iopub.status.busy": "2025-11-30T18:36:40.858361Z",
     "iopub.status.idle": "2025-11-30T18:36:41.141393Z",
     "shell.execute_reply": "2025-11-30T18:36:41.140330Z"
    },
    "papermill": {
     "duration": 0.288801,
     "end_time": "2025-11-30T18:36:41.142625",
     "exception": false,
     "start_time": "2025-11-30T18:36:40.853824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataParallel with 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2374521324.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL & OPTIMIZER\n",
    "# =============================================================================\n",
    "model = get_mbf(fp16=False, num_features=512).to(device)\n",
    "margin = SubCenterArcFace(\n",
    "    in_features=FEATURE_DIM,\n",
    "    out_features=NUM_CLASSES,\n",
    "    s=64.0,\n",
    "    m=0.4\n",
    ").to(device)\n",
    "\n",
    "if n_gpus > 1:\n",
    "    print(f\"Using DataParallel with {n_gpus} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "    margin = nn.DataParallel(margin)\n",
    "\n",
    "model = model.to(device)\n",
    "margin = margin.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([\n",
    "    {\"params\": model.parameters(), \"lr\": base_lr_backbone},\n",
    "    {\"params\": margin.parameters(), \"lr\": base_lr_margin}\n",
    "], momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6220c949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:41.152207Z",
     "iopub.status.busy": "2025-11-30T18:36:41.151964Z",
     "iopub.status.idle": "2025-11-30T18:36:41.156431Z",
     "shell.execute_reply": "2025-11-30T18:36:41.155927Z"
    },
    "papermill": {
     "duration": 0.010439,
     "end_time": "2025-11-30T18:36:41.157418",
     "exception": false,
     "start_time": "2025-11-30T18:36:41.146979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(path):\n",
    "    start_epoch = 0\n",
    "    resume_path = path\n",
    "\n",
    "    if os.path.exists(resume_path):\n",
    "        print(f\"==> Loading checkpoint from {resume_path}\")\n",
    "        checkpoint = torch.load(resume_path, map_location=device, weights_only=False)\n",
    "\n",
    "        model_to_load = model.module if hasattr(model, 'module') else model\n",
    "        margin_to_load = margin.module if hasattr(margin, 'module') else margin\n",
    "\n",
    "        model_to_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "        margin_to_load.load_state_dict(checkpoint['margin_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"==> Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    return start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b84a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:36:41.167400Z",
     "iopub.status.busy": "2025-11-30T18:36:41.167154Z",
     "iopub.status.idle": "2025-12-01T02:34:45.331259Z",
     "shell.execute_reply": "2025-12-01T02:34:45.330368Z"
    },
    "papermill": {
     "duration": 28689.328208,
     "end_time": "2025-12-01T02:34:50.489742",
     "exception": false,
     "start_time": "2025-11-30T18:36:41.161534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading checkpoint from //kaggle/input/checkpoint12/checkpoint_epoch_12.pt\n",
      "==> Resuming from epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 [LR: 0.010000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:39: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  train._scaler = GradScaler()\n",
      "/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 13/25 [LR: 0.010000]: 100%|██████████| 4375/4375 [44:28<00:00,  1.64it/s, loss=4.7729]\n",
      "Evaluating: 100%|██████████| 450/450 [04:35<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 13/25\n",
      "Learning Rate: Backbone=0.010000, Margin=0.050000\n",
      "Train Loss: 5.8582\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9542\n",
      "  - ROC AUC: 0.9869\n",
      "  - TAR@FAR1e-3: 0.8162\n",
      "  - TAR@FAR1e-4: 0.6785\n",
      "  - Threshold: 0.2218\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8162\n",
      "✓ Saved checkpoint at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 14/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [32:46<00:00,  2.23it/s, loss=3.5445]\n",
      "Evaluating: 100%|██████████| 450/450 [01:41<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 14/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.9486\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9606\n",
      "  - ROC AUC: 0.9887\n",
      "  - TAR@FAR1e-3: 0.8572\n",
      "  - TAR@FAR1e-4: 0.7498\n",
      "  - Threshold: 0.2208\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8572\n",
      "✓ Saved checkpoint at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 15/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [32:46<00:00,  2.22it/s, loss=4.6483]\n",
      "Evaluating: 100%|██████████| 450/450 [02:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 15/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.3805\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9608\n",
      "  - ROC AUC: 0.9887\n",
      "  - TAR@FAR1e-3: 0.8578\n",
      "  - TAR@FAR1e-4: 0.7616\n",
      "  - Threshold: 0.2184\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 16/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [32:45<00:00,  2.23it/s, loss=3.3048]\n",
      "Evaluating: 100%|██████████| 450/450 [02:09<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 16/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.2487\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9610\n",
      "  - ROC AUC: 0.9887\n",
      "  - TAR@FAR1e-3: 0.8601\n",
      "  - TAR@FAR1e-4: 0.7598\n",
      "  - Threshold: 0.2201\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8601\n",
      "✓ Saved checkpoint at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 17/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [32:43<00:00,  2.23it/s, loss=4.5213]\n",
      "Evaluating: 100%|██████████| 450/450 [01:50<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 17/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.1971\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9609\n",
      "  - ROC AUC: 0.9887\n",
      "  - TAR@FAR1e-3: 0.8613\n",
      "  - TAR@FAR1e-4: 0.7613\n",
      "  - Threshold: 0.2185\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8613\n",
      "✓ Saved checkpoint at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 18/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [33:42<00:00,  2.16it/s, loss=3.9364]\n",
      "Evaluating: 100%|██████████| 450/450 [02:03<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 18/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.1717\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9610\n",
      "  - ROC AUC: 0.9887\n",
      "  - TAR@FAR1e-3: 0.8614\n",
      "  - TAR@FAR1e-4: 0.7657\n",
      "  - Threshold: 0.2172\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 [LR: 0.001000]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 19/25 [LR: 0.001000]: 100%|██████████| 4375/4375 [32:44<00:00,  2.23it/s, loss=6.1081]\n",
      "Evaluating: 100%|██████████| 450/450 [01:59<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 19/25\n",
      "Learning Rate: Backbone=0.001000, Margin=0.005000\n",
      "Train Loss: 3.1541\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9609\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8620\n",
      "  - TAR@FAR1e-4: 0.7603\n",
      "  - Threshold: 0.2167\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 20/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [32:44<00:00,  2.23it/s, loss=3.2649]\n",
      "Evaluating: 100%|██████████| 450/450 [01:50<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 20/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.8148\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9610\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8634\n",
      "  - TAR@FAR1e-4: 0.7688\n",
      "  - Threshold: 0.2189\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8634\n",
      "✓ Saved checkpoint at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 21/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [32:47<00:00,  2.22it/s, loss=2.4869]\n",
      "Evaluating: 100%|██████████| 450/450 [02:09<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 21/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.7411\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9612\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8645\n",
      "  - TAR@FAR1e-4: 0.7675\n",
      "  - Threshold: 0.2184\n",
      "============================================================\n",
      "\n",
      "✓ Saved best model: TAR@FAR=0.8645\n",
      "✓ Saved checkpoint at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 22/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [32:48<00:00,  2.22it/s, loss=2.4036]\n",
      "Evaluating: 100%|██████████| 450/450 [01:52<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 22/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.7059\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9611\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8651\n",
      "  - TAR@FAR1e-4: 0.7657\n",
      "  - Threshold: 0.2179\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 23/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [32:45<00:00,  2.23it/s, loss=3.5952]\n",
      "Evaluating: 100%|██████████| 450/450 [02:18<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 23/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.6866\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9611\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8644\n",
      "  - TAR@FAR1e-4: 0.7688\n",
      "  - Threshold: 0.2170\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 24/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [32:53<00:00,  2.22it/s, loss=3.1970]\n",
      "Evaluating: 100%|██████████| 450/450 [01:56<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 24/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.6705\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9612\n",
      "  - ROC AUC: 0.9886\n",
      "  - TAR@FAR1e-3: 0.8639\n",
      "  - TAR@FAR1e-4: 0.7652\n",
      "  - Threshold: 0.2168\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 [LR: 0.000100]:   0%|          | 0/4375 [00:00<?, ?it/s]/tmp/ipykernel_19/908806943.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/kaggle/working/insightface/recognition/arcface_torch/backbones/mobilefacenet.py:135: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.fp16):\n",
      "Epoch 25/25 [LR: 0.000100]: 100%|██████████| 4375/4375 [33:12<00:00,  2.20it/s, loss=4.1574]\n",
      "Evaluating: 100%|██████████| 450/450 [02:12<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 25/25\n",
      "Learning Rate: Backbone=0.000100, Margin=0.000500\n",
      "Train Loss: 2.6607\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9611\n",
      "  - ROC AUC: 0.9885\n",
      "  - TAR@FAR1e-3: 0.8645\n",
      "  - TAR@FAR1e-4: 0.7623\n",
      "  - Threshold: 0.2168\n",
      "============================================================\n",
      "\n",
      "✓ Saved checkpoint at epoch 25\n",
      "\n",
      "✓ Training completed! Best TAR@FAR: 0.8645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5.858192835780552,\n",
       "  3.9486011795043945,\n",
       "  3.3805037422725133,\n",
       "  3.2486515484401157,\n",
       "  3.1970557082584925,\n",
       "  3.171720915930612,\n",
       "  3.1540656592777796,\n",
       "  2.814766678128924,\n",
       "  2.741131239782061,\n",
       "  2.7058794523784093,\n",
       "  2.686638185828073,\n",
       "  2.6704825529643466,\n",
       "  2.660726494925363],\n",
       " [0.9542366021509824,\n",
       "  0.9605557221418833,\n",
       "  0.9607728588035622,\n",
       "  0.960950851781333,\n",
       "  0.9608577932120421,\n",
       "  0.960950851781333,\n",
       "  0.9608718258534431,\n",
       "  0.9609981196260523,\n",
       "  0.961238151650017,\n",
       "  0.961119982038219,\n",
       "  0.9611495244411685,\n",
       "  0.9611731583635281,\n",
       "  0.9611347532396938],\n",
       " [0.9869045477417863,\n",
       "  0.9887044691870086,\n",
       "  0.9886916414637344,\n",
       "  0.9887142933921392,\n",
       "  0.9886622791840307,\n",
       "  0.9887055752319741,\n",
       "  0.9886359686595606,\n",
       "  0.9885553221013806,\n",
       "  0.9886280377569368,\n",
       "  0.9885501707541513,\n",
       "  0.9886482643555302,\n",
       "  0.9885761871050297,\n",
       "  0.9885100781241934],\n",
       " [0.816184214607832,\n",
       "  0.857236337746476,\n",
       "  0.8577873035614844,\n",
       "  0.8601122906736111,\n",
       "  0.8613412546363108,\n",
       "  0.861366365678818,\n",
       "  0.8619645993385456,\n",
       "  0.8634328567651364,\n",
       "  0.8645436511160381,\n",
       "  0.8651389305354709,\n",
       "  0.8644432069460097,\n",
       "  0.863940986095868,\n",
       "  0.8644609323877794])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train():\n",
    "    train_losses = []\n",
    "    accs = []\n",
    "    rocs = []\n",
    "    tfs = []\n",
    "    \n",
    "    early = EarlyStopping(patience=5, epsilon=0.001)\n",
    "    \n",
    "    start_epoch = load_checkpoint(\"//kaggle/input/checkpoint12/checkpoint_epoch_12.pt\")\n",
    "    \n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        model.train()\n",
    "        margin.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Get initial LR for display\n",
    "        lr_backbone, lr_margin = step_lr(\n",
    "            optimizer, base_lr_backbone, base_lr_margin,\n",
    "            epoch, milestones=step_milestones, gamma=step_gamma\n",
    "        )\n",
    "        pbar = tqdm(\n",
    "            enumerate(train_loader), \n",
    "            total=len(train_loader), \n",
    "            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {lr_backbone:.6f}]\"\n",
    "        )\n",
    "\n",
    "        for step, (inputs, targets) in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward (with mixed precision if enabled)\n",
    "            try:\n",
    "                # Try mixed precision first\n",
    "                from torch.cuda.amp import autocast, GradScaler\n",
    "                if not hasattr(train, '_scaler_initialized'):\n",
    "                    train._scaler = GradScaler()\n",
    "                    train._scaler_initialized = True\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                    logits = margin(outputs, targets)\n",
    "                    loss = criterion(logits, targets)\n",
    "                \n",
    "                # Backward with mixed precision\n",
    "                train._scaler.scale(loss).backward()\n",
    "                train._scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n",
    "                train._scaler.step(optimizer)\n",
    "                train._scaler.update()\n",
    "                \n",
    "            except:\n",
    "                # Fallback to FP32 if mixed precision fails\n",
    "                outputs = model(inputs)\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                logits = margin(outputs, targets)\n",
    "                loss = criterion(logits, targets)\n",
    "                \n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                torch.nn.utils.clip_grad_norm_(margin.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # ==================== EVALUATION ====================\n",
    "        model.eval()\n",
    "        margin.eval()\n",
    "\n",
    "        embs = []\n",
    "        labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "\n",
    "                embs.append(outputs.cpu())\n",
    "                labels_list.append(targets.cpu())\n",
    "\n",
    "        eval_res = evaluate(embs, labels_list, max_per_class=50, n_linspace=1000)\n",
    "        tar_far1 = eval_res[\"tar_far1\"]\n",
    "        tar_far2 = eval_res[\"tar_far2\"]\n",
    "\n",
    "        # Append\n",
    "        train_losses.append(avg_train_loss)\n",
    "        accs.append(eval_res['accuracy'])\n",
    "        rocs.append(eval_res['roc_auc'])\n",
    "        tfs.append(tar_far1)\n",
    "\n",
    "        # Get current learning rates\n",
    "        current_lr_backbone = optimizer.param_groups[0]['lr']\n",
    "        current_lr_margin = optimizer.param_groups[1]['lr']\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Learning Rate: Backbone={current_lr_backbone:.6f}, Margin={current_lr_margin:.6f}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Eval Metrics:\")\n",
    "        print(f\"  - Accuracy: {eval_res['accuracy']:.4f}\")\n",
    "        print(f\"  - ROC AUC: {eval_res['roc_auc']:.4f}\")\n",
    "        print(f\"  - TAR@FAR1e-3: {eval_res['tar_far1']:.4f}\")\n",
    "        print(f\"  - TAR@FAR1e-4: {eval_res['tar_far2']:.4f}\")\n",
    "        print(f\"  - Threshold: {eval_res['threshold']:.4f}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        # Early Stopping (with multi-GPU support)\n",
    "        early.step(tar_far1, model, margin)\n",
    "        \n",
    "        # Save checkpoint every 5 epochs (unwrap DataParallel)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        margin_to_save = margin.module if hasattr(margin, 'module') else margin\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'margin_state_dict': margin_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'tar_far1e-3': tar_far1,\n",
    "            'tar_far1e-4': tar_far2,\n",
    "            'n_gpus': n_gpus\n",
    "        }, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "        print(f\"✓ Saved checkpoint at epoch {epoch+1}\")\n",
    "        \n",
    "        if early.should_stop:\n",
    "            print(\"⚠ Training stopped early.\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n✓ Training completed! Best TAR@FAR: {early.best_acc:.4f}\")\n",
    "\n",
    "    return train_losses, accs, rocs, tfs\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5207179",
   "metadata": {
    "papermill": {
     "duration": 5.188477,
     "end_time": "2025-12-01T02:35:00.874901",
     "exception": false,
     "start_time": "2025-12-01T02:34:55.686424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 442595,
     "sourceId": 1003630,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8770864,
     "sourceId": 13779592,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8827871,
     "sourceId": 13857610,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808355,
     "sourceId": 13857621,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808735,
     "sourceId": 13858477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867027,
     "sourceId": 13915972,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867060,
     "sourceId": 13916389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867030,
     "sourceId": 13916391,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8868944,
     "sourceId": 13920400,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8872641,
     "sourceId": 13923640,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8881006,
     "sourceId": 13935592,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28799.86406,
   "end_time": "2025-12-01T02:35:09.045629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T18:35:09.181569",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
