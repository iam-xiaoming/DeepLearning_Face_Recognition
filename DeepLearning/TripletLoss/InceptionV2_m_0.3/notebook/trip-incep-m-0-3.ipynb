{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1003630,"sourceType":"datasetVersion","datasetId":442595},{"sourceId":13779592,"sourceType":"datasetVersion","datasetId":8770864},{"sourceId":13857610,"sourceType":"datasetVersion","datasetId":8827871},{"sourceId":13857621,"sourceType":"datasetVersion","datasetId":8808355},{"sourceId":13858477,"sourceType":"datasetVersion","datasetId":8808735},{"sourceId":13915972,"sourceType":"datasetVersion","datasetId":8867027},{"sourceId":13916389,"sourceType":"datasetVersion","datasetId":8867060},{"sourceId":13916391,"sourceType":"datasetVersion","datasetId":8867030}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":24747.124394,"end_time":"2025-11-25T11:27:30.116533","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-25T04:35:02.992139","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"135d9faf-699e-48db-b75f-7c824993a1dc","cell_type":"code","source":"!pip install -q /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.2.7-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:19:26.742517Z","iopub.execute_input":"2025-11-29T10:19:26.742710Z","iopub.status.idle":"2025-11-29T10:19:31.162954Z","shell.execute_reply.started":"2025-11-29T10:19:26.742689Z","shell.execute_reply":"2025-11-29T10:19:31.161977Z"}},"outputs":[],"execution_count":1},{"id":"5a576b15","cell_type":"code","source":"import os\nimport sys\nimport glob\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, Sampler, DataLoader\nimport random\nfrom collections import defaultdict\nfrom facenet_pytorch import InceptionResnetV1\nimport torch.nn as nn\nimport numpy as np\nfrom torchvision import transforms\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport time\nfrom sklearn.metrics import recall_score, precision_score\nimport itertools\nimport copy\nimport matplotlib.pyplot as plt\nfrom torch.cuda.amp import autocast, GradScaler\nSCORE_DIR = \"/kaggle/input/arc-scores\"\nif SCORE_DIR not in sys.path:\n    sys.path.append(SCORE_DIR)\nimport arc_scores\nHELPER_DIR = \"/kaggle/input/helper-py\"\nif HELPER_DIR not in sys.path:\n    sys.path.append(HELPER_DIR)\nimport helper\nEVULATE_DIR = \"/kaggle/input/evulate\"\nif EVULATE_DIR not in sys.path:\n    sys.path.append(EVULATE_DIR)\nimport evaluate\n\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2025-11-29T10:19:48.372603Z","iopub.execute_input":"2025-11-29T10:19:48.373410Z","iopub.status.idle":"2025-11-29T10:19:55.986052Z","shell.execute_reply.started":"2025-11-29T10:19:48.373367Z","shell.execute_reply":"2025-11-29T10:19:55.985198Z"},"id":"5a576b15","papermill":{"duration":11.508584,"end_time":"2025-11-25T04:35:23.379370","exception":false,"start_time":"2025-11-25T04:35:11.870786","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"016973f6","cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-11-29T10:22:37.359295Z","iopub.execute_input":"2025-11-29T10:22:37.359586Z","iopub.status.idle":"2025-11-29T10:22:37.423601Z","shell.execute_reply.started":"2025-11-29T10:22:37.359563Z","shell.execute_reply":"2025-11-29T10:22:37.422823Z"},"id":"016973f6","outputId":"3dc29e49-1581-458d-e03f-5aebd17db306","papermill":{"duration":0.06109,"end_time":"2025-11-25T04:35:23.445412","exception":false,"start_time":"2025-11-25T04:35:23.384322","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":9},{"id":"6e11101a","cell_type":"code","source":"class FaceFolderDataset(Dataset):\n    def __init__(self, root, transform=None):\n        self.root = root # directory\n        self.transform = transform\n        self.samples = []   # (img_path, label)\n        self.labels = []\n\n        persons = sorted(os.listdir(root))\n        for label, person in enumerate(persons):\n            self.labels.append(label)\n            folder = os.path.join(root, person)\n            if not os.path.isdir(folder):\n                continue\n            imgs = glob.glob(os.path.join(folder, \"*\"))\n            for img_path in imgs:\n                self.samples.append((img_path, label))\n\n    def __len__(self):\n        return len(self.samples)\n\n    # allow to use [] to access the index\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2025-11-29T10:20:50.953656Z","iopub.execute_input":"2025-11-29T10:20:50.954399Z","iopub.status.idle":"2025-11-29T10:20:50.960893Z","shell.execute_reply.started":"2025-11-29T10:20:50.954374Z","shell.execute_reply":"2025-11-29T10:20:50.960107Z"},"id":"6e11101a","papermill":{"duration":0.011494,"end_time":"2025-11-25T04:35:23.461666","exception":false,"start_time":"2025-11-25T04:35:23.450172","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"49af76fe","cell_type":"code","source":"class PKSampler(Sampler):\n    def __init__(self, dataset, P, K, samples_per_class_per_epoch=5):\n        \"\"\"\n        dataset: FaceFolderDataset object\n        P: số classes mỗi batch\n        K: số samples mỗi class\n        \"\"\"\n        self.P = P\n        self.K = K\n        self.samples_per_class = samples_per_class_per_epoch\n        self.label2indices = defaultdict(list)\n\n        # lấy labels từ samples\n        for idx, (_, label) in enumerate(dataset.samples):\n            self.label2indices[label].append(idx)\n\n        self.labels = list(self.label2indices.keys())\n        self.n_classes = len(self.labels)\n\n        # Tính số batches\n        self.batches_per_epoch = (self.n_classes * self.samples_per_class + P - 1) // P\n\n        total_images = sum(len(indices) for indices in self.label2indices.values())\n\n        print(f\"\\n{'='*60}\")\n        print(f\"PKSampler Info:\")\n        print(f\"{'='*60}\")\n        print(f\"Total images: {total_images}\")\n        print(f\"Total classes: {self.n_classes}\")\n        print(f\"Avg images/class: {total_images/self.n_classes:.1f}\")\n        print(f\"Samples per class per epoch: {self.samples_per_class}\")\n        print(f\"Batches per epoch: {self.batches_per_epoch}\")\n        print(f\"Total samples per epoch: {self.batches_per_epoch * P * K}\")\n        print(f\"Coverage: {(self.batches_per_epoch * P * K) / total_images * 100:.1f}%\")\n        print(f\"Expected time per epoch: ~{self.batches_per_epoch * 0.15:.1f}s (assuming 0.15s/batch)\")\n        print(f\"{'='*60}\\n\")\n\n    def __iter__(self):\n        # Mỗi class lặp lại samples_per_class lần\n        class_pool = []\n        for _ in range(self.samples_per_class):\n            shuffled = self.labels.copy()\n            random.shuffle(shuffled)\n            class_pool.extend(shuffled)\n\n        random.shuffle(class_pool)\n\n        for batch_idx in range(self.batches_per_epoch):\n            start = batch_idx * self.P\n            batch_labels = class_pool[start:start + self.P]\n\n            if len(batch_labels) < self.P:\n                break\n\n            batch = []\n            for label in batch_labels:\n                indices = self.label2indices[label]\n\n                if len(indices) >= self.K:\n                    selected = random.sample(indices, k=self.K)\n                else:\n                    selected = random.choices(indices, k=self.K)\n\n                batch.extend(selected)\n\n            yield from batch\n\n    def __len__(self):\n        return self.batches_per_epoch * self.P * self.K","metadata":{"execution":{"iopub.status.busy":"2025-11-29T10:20:54.293106Z","iopub.execute_input":"2025-11-29T10:20:54.293405Z","iopub.status.idle":"2025-11-29T10:20:54.303294Z","shell.execute_reply.started":"2025-11-29T10:20:54.293383Z","shell.execute_reply":"2025-11-29T10:20:54.302561Z"},"id":"49af76fe","papermill":{"duration":0.013259,"end_time":"2025-11-25T04:35:23.479439","exception":false,"start_time":"2025-11-25T04:35:23.466180","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"amAQgd0-XkmW","cell_type":"code","source":"class BatchHardTripletLoss(nn.Module):\n    def __init__(self, margin=0.2, mode='semi_hard'):\n        super().__init__()\n        self.margin = margin\n        self.mode = mode\n\n    def update_strategy(self, mode):\n        self.mode = mode\n\n    def forward(self, embs, labels):\n        dist = torch.cdist(embs, embs)\n\n        labels = labels.view(-1, 1)\n        pos_mask = labels.eq(labels.t())\n        neg_mask = ~pos_mask\n\n        eye = torch.eye(len(labels), dtype=torch.bool, device=labels.device)\n        pos_mask[eye] = False\n\n        # Kiểm tra có positive không (mỗi sample cần ít nhất 1 positive)\n        valid_samples = pos_mask.any(dim=1)\n\n        if self.mode == \"semi_hard\":\n            # Dùng CLOSEST positive (theo paper gốc FaceNet)\n            pos_dist = dist.clone()\n            pos_dist[~pos_mask] = 1e9\n            closest_pos = pos_dist.min(dim=1)[0]  # MIN - positive gần nhất\n\n            neg_dist = dist.clone()\n            neg_dist[~neg_mask] = 1e9\n\n            # Semi-hard negative: d(anchor, pos) < d(anchor, neg) < d(anchor, pos) + margin\n            semi_mask = (neg_dist > closest_pos.unsqueeze(1)) & \\\n                        (neg_dist < (closest_pos + self.margin).unsqueeze(1))\n\n            semi_neg = neg_dist.clone()\n            semi_neg[~semi_mask] = 1e9\n            semi_neg = semi_neg.min(dim=1)[0]\n\n            # Fallback: nếu không tìm được semi-hard, dùng hardest negative\n            hardest_neg = neg_dist.min(dim=1)[0]\n            semi_neg = torch.where(semi_neg >= 1e6, hardest_neg, semi_neg)\n\n            loss = torch.relu(closest_pos - semi_neg + self.margin)\n\n            # Chỉ tính loss cho samples có positive\n            if valid_samples.all():\n                return loss.mean()\n            else:\n                return loss[valid_samples].mean() if valid_samples.any() else torch.tensor(0.0, device=embs.device)\n\n        # Batch-hard mode: dùng hardest positive và hardest negative\n        # Hardest positive: positive xa nhất\n        pos_dist = dist.clone()\n        pos_dist[~pos_mask] = -1e9\n        hardest_pos = pos_dist.max(dim=1)[0]\n\n        # Hardest negative: negative gần nhất\n        neg_dist = dist.clone()\n        neg_dist[~neg_mask] = 1e9\n        hardest_neg = neg_dist.min(dim=1)[0]\n\n        loss = torch.relu(hardest_pos - hardest_neg + self.margin)\n\n        # Chỉ tính loss cho samples có positive\n        if valid_samples.all():\n            return loss.mean()\n        else:\n            return loss[valid_samples].mean() if valid_samples.any() else torch.tensor(0.0, device=embs.device)","metadata":{"id":"amAQgd0-XkmW","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:25:11.495263Z","iopub.execute_input":"2025-11-29T10:25:11.495515Z","iopub.status.idle":"2025-11-29T10:25:11.504957Z","shell.execute_reply.started":"2025-11-29T10:25:11.495499Z","shell.execute_reply":"2025-11-29T10:25:11.504186Z"}},"outputs":[],"execution_count":16},{"id":"5MA8YDt5orHb","cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((160, 160)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((160, 160)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"id":"5MA8YDt5orHb","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:21:01.682361Z","iopub.execute_input":"2025-11-29T10:21:01.682662Z","iopub.status.idle":"2025-11-29T10:21:01.687615Z","shell.execute_reply.started":"2025-11-29T10:21:01.682638Z","shell.execute_reply":"2025-11-29T10:21:01.686947Z"}},"outputs":[],"execution_count":5},{"id":"qW0N8kiFmUKn","cell_type":"code","source":"train_path = '/kaggle/input/train-ds/train'\nval_path = '/kaggle/input/val-ds/val'\n\nP, K = 256, 4\n\ntrain_dataset = FaceFolderDataset(train_path, transform=train_transform)\nval_dataset = FaceFolderDataset(val_path, transform=val_transform)\n\n# CÁCH 1: Truyền dataset object\ntrain_sampler = PKSampler(\n    dataset=train_dataset,\n    P=P,\n    K=K,\n    samples_per_class_per_epoch=10  # Mỗi class sample 5 lần/epoch\n)\n\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=P*K,\n    sampler=train_sampler,\n    num_workers=2,\n    pin_memory=True,\n    persistent_workers=True\n)\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size=512,\n    num_workers=2,\n    shuffle=False,\n    pin_memory=True,\n    persistent_workers=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qW0N8kiFmUKn","outputId":"0553a09c-1213-4898-d4bb-1582cab5af09","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:21:05.500160Z","iopub.execute_input":"2025-11-29T10:21:05.500447Z","iopub.status.idle":"2025-11-29T10:22:17.236132Z","shell.execute_reply.started":"2025-11-29T10:21:05.500422Z","shell.execute_reply":"2025-11-29T10:22:17.235313Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nPKSampler Info:\n============================================================\nTotal images: 1119807\nTotal classes: 5115\nAvg images/class: 218.9\nSamples per class per epoch: 10\nBatches per epoch: 200\nTotal samples per epoch: 204800\nCoverage: 18.3%\nExpected time per epoch: ~30.0s (assuming 0.15s/batch)\n============================================================\n\n","output_type":"stream"}],"execution_count":6},{"id":"62aeee6a","cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, epsilon=0.001, save_path=\"best.pt\"):\n        self.patience = patience\n        self.save_path = save_path\n        self.epsilon = epsilon\n        self.best_acc = -1\n        self.counter = 0\n        self.should_stop = False\n        self.phase = 1\n\n    def step(self, val_acc, model):\n        if val_acc > self.best_acc + self.epsilon:\n            self.best_acc = val_acc\n            self.counter = 0\n\n            model_to_save = model.module if hasattr(model, 'module') else model\n\n            checkpoint = {\n                'model_state_dict': model_to_save.state_dict(),\n                'best_tar_far': self.best_acc\n            }\n            torch.save(checkpoint, self.save_path)\n            print(f\"Saved best model: TAR@FAR1e-3={val_acc:.4f}\")\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                if self.phase == 1:\n                    print(\"!!! UPDATE STRATEGY TO HARD MINING !!!\")\n                    self.phase = 2\n                    self.counter = 0\n                    self.patience = 5\n                elif self.phase == 2:\n                    self.should_stop = True\n                    print(\"Early stopping triggered!\")","metadata":{"id":"62aeee6a","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:22:17.237278Z","iopub.execute_input":"2025-11-29T10:22:17.237529Z","iopub.status.idle":"2025-11-29T10:22:17.244542Z","shell.execute_reply.started":"2025-11-29T10:22:17.237512Z","shell.execute_reply":"2025-11-29T10:22:17.243793Z"}},"outputs":[],"execution_count":7},{"id":"bcfd6b22","cell_type":"code","source":"NUM_EPOCHS = 30\nlearning_rate = 5e-6\n\nmodel = InceptionResnetV1(pretrained='casia-webface')\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4, betas=(0.9, 0.999))\ncriterion = BatchHardTripletLoss(margin=0.3, mode='semi_hard')","metadata":{"execution":{"iopub.status.busy":"2025-11-29T10:25:24.110967Z","iopub.execute_input":"2025-11-29T10:25:24.111677Z","iopub.status.idle":"2025-11-29T10:25:24.563136Z","shell.execute_reply.started":"2025-11-29T10:25:24.111654Z","shell.execute_reply":"2025-11-29T10:25:24.562519Z"},"id":"bcfd6b22","papermill":{"duration":9.452267,"end_time":"2025-11-25T04:36:35.104733","exception":false,"start_time":"2025-11-25T04:36:25.652466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"645731be","cell_type":"code","source":"def train():\n    train_losses = []\n    test_losses = []\n    tarfar3s = []\n    tarfar4s = []\n    accs = []\n    rocs = []\n\n    # early stopping\n    early = EarlyStopping(patience=3, save_path=\"best.pt\")\n    is_update = False\n\n    # FP16 scaler\n    scaler = GradScaler()\n\n    for epoch in range(NUM_EPOCHS):\n        model.train()\n        train_loss = []\n\n        pbar = tqdm(\n            enumerate(train_loader),\n            total=len(train_loader),\n            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {learning_rate:.6f}]\"\n        )\n\n        for step, (inputs, targets) in pbar:\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            optimizer.zero_grad()\n\n            # ===========================\n            #       FP16 TRAINING\n            # ===========================\n            with autocast(dtype=torch.float16):\n                outputs = model(inputs)\n                outputs = F.normalize(outputs, p=2, dim=1)\n                loss = criterion(outputs, targets)\n\n            # Scaler backward\n            scaler.scale(loss).backward()\n\n            # Clip grad norm (có scale)\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n\n            # Step optimizer\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss.append(loss.item())\n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n        train_loss = np.mean(train_loss)\n\n        # ==================== EVALUATION ====================\n        model.eval()\n        test_loss = []\n        embs = []\n        labels = []\n\n        with torch.no_grad():\n            # Evaluation không cần autocast\n            for inputs, targets in tqdm(val_loader):\n                inputs, targets = inputs.to(device), targets.to(device)\n\n                with autocast(dtype=torch.float16):\n                    outputs = model(inputs)\n                    outputs = F.normalize(outputs, p=2, dim=1)\n                    loss = criterion(outputs, targets)\n\n                test_loss.append(loss.item())\n                embs.append(outputs.cpu())\n                labels.append(targets.cpu())\n\n        test_loss = np.mean(test_loss)\n\n        eval_res = evaluate.evaluate(embs, labels, max_per_class=50, n_linspace=1000)\n\n        # early stopping\n        early.step(eval_res[\"tar_far_3\"], model)\n\n        # save ckpt + print\n        helper.save_checkpoint(model, epoch, optimizer, train_loss,\n                               eval_res[\"tar_far_3\"], eval_res[\"tar_far_4\"])\n        helper.print_results(optimizer, epoch, NUM_EPOCHS, train_loss, eval_res)\n\n        # save scores\n        train_losses.append(train_loss)\n        test_losses.append(test_loss)\n        tarfar3s.append(eval_res[\"tar_far_3\"])\n        tarfar4s.append(eval_res[\"tar_far_4\"])\n        accs.append(eval_res[\"accuracy\"])\n        rocs.append(eval_res[\"roc_auc\"])\n\n        # Switch to HARD mining\n        if early.phase == 2 and not is_update:\n            is_update = True\n            criterion.update_strategy(\"hard\")\n            print(\"Switch loss to HARD mining!\")\n\n        if early.should_stop:\n            break\n\n    print(f\"\\nTraining completed! Best TAR@FAR1e-3: {early.best_acc:.4f}\")\n\n    return train_losses, test_losses, tarfar3s, tarfar4s, accs, rocs","metadata":{"execution":{"iopub.status.busy":"2025-11-29T10:25:27.726699Z","iopub.execute_input":"2025-11-29T10:25:27.727331Z","iopub.status.idle":"2025-11-29T10:25:27.737803Z","shell.execute_reply.started":"2025-11-29T10:25:27.727308Z","shell.execute_reply":"2025-11-29T10:25:27.737002Z"},"id":"645731be","papermill":{"duration":24309.91624,"end_time":"2025-11-25T11:21:45.040793","exception":false,"start_time":"2025-11-25T04:36:35.124553","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"id":"ec5a73d2","cell_type":"code","source":"train_losses, test_losses, tarfar3s, tarfar4s, accs, rocs = train()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ec5a73d2","outputId":"311439b0-f5eb-4bef-b942-7da580479107","papermill":{"duration":0.809307,"end_time":"2025-11-25T11:27:25.680824","exception":false,"start_time":"2025-11-25T11:27:24.871517","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:25:28.291013Z","iopub.execute_input":"2025-11-29T10:25:28.291807Z","iopub.status.idle":"2025-11-29T18:38:06.787169Z","shell.execute_reply.started":"2025-11-29T10:25:28.291782Z","shell.execute_reply":"2025-11-29T18:38:06.785486Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/4248335842.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\nEpoch 1/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 1/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:44<00:03,  3.84s/it, loss=0.1444]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [06:26<00:00,  1.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.6980\nSaved checkpoint at epoch 1\n\n============================================================\nEpoch 1/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1559\nEval Metrics:\n  - Accuracy: 0.9464\n  - ROC AUC: 0.9856\n  - TAR@FAR1e-3: 0.6980\n  - TAR@FAR1e-4: 0.4892\n  - Threshold: 0.2405\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 2/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [13:44<00:04,  4.14s/it, loss=0.1292]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:22<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7214\nSaved checkpoint at epoch 2\n\n============================================================\nEpoch 2/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1415\nEval Metrics:\n  - Accuracy: 0.9493\n  - ROC AUC: 0.9869\n  - TAR@FAR1e-3: 0.7214\n  - TAR@FAR1e-4: 0.5279\n  - Threshold: 0.2442\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 3/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:31<00:03,  3.78s/it, loss=0.1263]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:23<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7318\nSaved checkpoint at epoch 3\n\n============================================================\nEpoch 3/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1339\nEval Metrics:\n  - Accuracy: 0.9508\n  - ROC AUC: 0.9874\n  - TAR@FAR1e-3: 0.7318\n  - TAR@FAR1e-4: 0.5423\n  - Threshold: 0.2481\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 4/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:21<00:03,  3.73s/it, loss=0.1265]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:22<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7393\nSaved checkpoint at epoch 4\n\n============================================================\nEpoch 4/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1305\nEval Metrics:\n  - Accuracy: 0.9521\n  - ROC AUC: 0.9878\n  - TAR@FAR1e-3: 0.7393\n  - TAR@FAR1e-4: 0.5535\n  - Threshold: 0.2520\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 5/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:18<00:03,  3.71s/it, loss=0.1225]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:43<00:00,  1.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7443\nSaved checkpoint at epoch 5\n\n============================================================\nEpoch 5/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1270\nEval Metrics:\n  - Accuracy: 0.9525\n  - ROC AUC: 0.9879\n  - TAR@FAR1e-3: 0.7443\n  - TAR@FAR1e-4: 0.5670\n  - Threshold: 0.2578\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 6/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [13:19<00:04,  4.02s/it, loss=0.1134]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:26<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7474\nSaved checkpoint at epoch 6\n\n============================================================\nEpoch 6/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1250\nEval Metrics:\n  - Accuracy: 0.9531\n  - ROC AUC: 0.9882\n  - TAR@FAR1e-3: 0.7474\n  - TAR@FAR1e-4: 0.5681\n  - Threshold: 0.2591\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 7/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:26<00:03,  3.75s/it, loss=0.1352]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:47<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7525\nSaved checkpoint at epoch 7\n\n============================================================\nEpoch 7/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1229\nEval Metrics:\n  - Accuracy: 0.9534\n  - ROC AUC: 0.9883\n  - TAR@FAR1e-3: 0.7525\n  - TAR@FAR1e-4: 0.5784\n  - Threshold: 0.2587\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 8/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:26<00:03,  3.75s/it, loss=0.1236]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:09<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7552\nSaved checkpoint at epoch 8\n\n============================================================\nEpoch 8/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1205\nEval Metrics:\n  - Accuracy: 0.9539\n  - ROC AUC: 0.9885\n  - TAR@FAR1e-3: 0.7552\n  - TAR@FAR1e-4: 0.5811\n  - Threshold: 0.2637\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 9/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:24<00:03,  3.74s/it, loss=0.1125]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:59<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 9\n\n============================================================\nEpoch 9/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1198\nEval Metrics:\n  - Accuracy: 0.9541\n  - ROC AUC: 0.9886\n  - TAR@FAR1e-3: 0.7559\n  - TAR@FAR1e-4: 0.5826\n  - Threshold: 0.2610\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 10/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:33<00:03,  3.79s/it, loss=0.1199]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:08<00:00,  1.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7594\nSaved checkpoint at epoch 10\n\n============================================================\nEpoch 10/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1181\nEval Metrics:\n  - Accuracy: 0.9545\n  - ROC AUC: 0.9887\n  - TAR@FAR1e-3: 0.7594\n  - TAR@FAR1e-4: 0.5908\n  - Threshold: 0.2623\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 11/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:28<00:03,  3.76s/it, loss=0.1061]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:05<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7629\nSaved checkpoint at epoch 11\n\n============================================================\nEpoch 11/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1173\nEval Metrics:\n  - Accuracy: 0.9545\n  - ROC AUC: 0.9887\n  - TAR@FAR1e-3: 0.7629\n  - TAR@FAR1e-4: 0.5917\n  - Threshold: 0.2639\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 12/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:31<00:03,  3.78s/it, loss=0.1156]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:57<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7643\nSaved checkpoint at epoch 12\n\n============================================================\nEpoch 12/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1152\nEval Metrics:\n  - Accuracy: 0.9548\n  - ROC AUC: 0.9888\n  - TAR@FAR1e-3: 0.7643\n  - TAR@FAR1e-4: 0.5967\n  - Threshold: 0.2619\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 13/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:28<00:03,  3.76s/it, loss=0.1063]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:57<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 13\n\n============================================================\nEpoch 13/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1153\nEval Metrics:\n  - Accuracy: 0.9551\n  - ROC AUC: 0.9888\n  - TAR@FAR1e-3: 0.7646\n  - TAR@FAR1e-4: 0.6016\n  - Threshold: 0.2670\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 14/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:29<00:03,  3.77s/it, loss=0.1100]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:58<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7671\nSaved checkpoint at epoch 14\n\n============================================================\nEpoch 14/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1138\nEval Metrics:\n  - Accuracy: 0.9552\n  - ROC AUC: 0.9889\n  - TAR@FAR1e-3: 0.7671\n  - TAR@FAR1e-4: 0.6017\n  - Threshold: 0.2605\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 15/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:30<00:03,  3.77s/it, loss=0.1128]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:58<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 15\n\n============================================================\nEpoch 15/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1122\nEval Metrics:\n  - Accuracy: 0.9553\n  - ROC AUC: 0.9889\n  - TAR@FAR1e-3: 0.7675\n  - TAR@FAR1e-4: 0.6025\n  - Threshold: 0.2681\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 16/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:32<00:03,  3.78s/it, loss=0.1154]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:05<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7702\nSaved checkpoint at epoch 16\n\n============================================================\nEpoch 16/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1119\nEval Metrics:\n  - Accuracy: 0.9554\n  - ROC AUC: 0.9889\n  - TAR@FAR1e-3: 0.7702\n  - TAR@FAR1e-4: 0.6163\n  - Threshold: 0.2682\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 17/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:42<00:03,  3.83s/it, loss=0.1139]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:59<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 17\n\n============================================================\nEpoch 17/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1109\nEval Metrics:\n  - Accuracy: 0.9555\n  - ROC AUC: 0.9890\n  - TAR@FAR1e-3: 0.7701\n  - TAR@FAR1e-4: 0.6067\n  - Threshold: 0.2684\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 18/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:23<00:03,  3.73s/it, loss=0.1134]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:02<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7714\nSaved checkpoint at epoch 18\n\n============================================================\nEpoch 18/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1102\nEval Metrics:\n  - Accuracy: 0.9557\n  - ROC AUC: 0.9891\n  - TAR@FAR1e-3: 0.7714\n  - TAR@FAR1e-4: 0.6134\n  - Threshold: 0.2709\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 19/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:20<00:03,  3.72s/it, loss=0.1042]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:04<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 19\n\n============================================================\nEpoch 19/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1096\nEval Metrics:\n  - Accuracy: 0.9556\n  - ROC AUC: 0.9890\n  - TAR@FAR1e-3: 0.7722\n  - TAR@FAR1e-4: 0.6078\n  - Threshold: 0.2711\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 20/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:20<00:03,  3.72s/it, loss=0.1077]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:00<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7727\nSaved checkpoint at epoch 20\n\n============================================================\nEpoch 20/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1089\nEval Metrics:\n  - Accuracy: 0.9558\n  - ROC AUC: 0.9891\n  - TAR@FAR1e-3: 0.7727\n  - TAR@FAR1e-4: 0.6158\n  - Threshold: 0.2689\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 21/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:32<00:03,  3.78s/it, loss=0.1030]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:47<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 21\n\n============================================================\nEpoch 21/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1078\nEval Metrics:\n  - Accuracy: 0.9562\n  - ROC AUC: 0.9892\n  - TAR@FAR1e-3: 0.7733\n  - TAR@FAR1e-4: 0.6105\n  - Threshold: 0.2699\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 22/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:24<00:03,  3.74s/it, loss=0.1039]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:53<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7752\nSaved checkpoint at epoch 22\n\n============================================================\nEpoch 22/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1079\nEval Metrics:\n  - Accuracy: 0.9562\n  - ROC AUC: 0.9891\n  - TAR@FAR1e-3: 0.7752\n  - TAR@FAR1e-4: 0.6132\n  - Threshold: 0.2714\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 23/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [17:09<00:05,  5.17s/it, loss=0.0992]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:26<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 23\n\n============================================================\nEpoch 23/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1064\nEval Metrics:\n  - Accuracy: 0.9563\n  - ROC AUC: 0.9893\n  - TAR@FAR1e-3: 0.7762\n  - TAR@FAR1e-4: 0.6174\n  - Threshold: 0.2723\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 24/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:32<00:03,  3.78s/it, loss=0.1061]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:22<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7768\nSaved checkpoint at epoch 24\n\n============================================================\nEpoch 24/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1064\nEval Metrics:\n  - Accuracy: 0.9562\n  - ROC AUC: 0.9892\n  - TAR@FAR1e-3: 0.7768\n  - TAR@FAR1e-4: 0.6129\n  - Threshold: 0.2699\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 25/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:20<00:03,  3.72s/it, loss=0.0984]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:54<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 25\n\n============================================================\nEpoch 25/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1057\nEval Metrics:\n  - Accuracy: 0.9563\n  - ROC AUC: 0.9892\n  - TAR@FAR1e-3: 0.7763\n  - TAR@FAR1e-4: 0.6182\n  - Threshold: 0.2707\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 26/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:23<00:03,  3.74s/it, loss=0.0936]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:03<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 26\n\n============================================================\nEpoch 26/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1051\nEval Metrics:\n  - Accuracy: 0.9565\n  - ROC AUC: 0.9893\n  - TAR@FAR1e-3: 0.7767\n  - TAR@FAR1e-4: 0.6192\n  - Threshold: 0.2718\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 27/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:26<00:03,  3.75s/it, loss=0.1059]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:58<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7787\nSaved checkpoint at epoch 27\n\n============================================================\nEpoch 27/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1048\nEval Metrics:\n  - Accuracy: 0.9565\n  - ROC AUC: 0.9892\n  - TAR@FAR1e-3: 0.7787\n  - TAR@FAR1e-4: 0.6169\n  - Threshold: 0.2690\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 28/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:15<00:03,  3.69s/it, loss=0.0998]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:18<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint at epoch 28\n\n============================================================\nEpoch 28/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1039\nEval Metrics:\n  - Accuracy: 0.9567\n  - ROC AUC: 0.9893\n  - TAR@FAR1e-3: 0.7782\n  - TAR@FAR1e-4: 0.6114\n  - Threshold: 0.2667\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 29/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:28<00:03,  3.76s/it, loss=0.1028]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [03:01<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7799\nSaved checkpoint at epoch 29\n\n============================================================\nEpoch 29/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1036\nEval Metrics:\n  - Accuracy: 0.9570\n  - ROC AUC: 0.9894\n  - TAR@FAR1e-3: 0.7799\n  - TAR@FAR1e-4: 0.6212\n  - Threshold: 0.2705\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/30 [LR: 0.000005]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\nEpoch 30/30 [LR: 0.000005]: 100%|█████████▉| 199/200 [12:36<00:03,  3.80s/it, loss=0.1032]\n  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_47/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(dtype=torch.float16):\n100%|██████████| 225/225 [02:59<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved best model: TAR@FAR1e-3=0.7820\nSaved checkpoint at epoch 30\n\n============================================================\nEpoch 30/30\nLearning Rate: Backbone=0.000005\nTrain Loss: 0.1027\nEval Metrics:\n  - Accuracy: 0.9568\n  - ROC AUC: 0.9893\n  - TAR@FAR1e-3: 0.7820\n  - TAR@FAR1e-4: 0.6306\n  - Threshold: 0.2706\n============================================================\n\n\nTraining completed! Best TAR@FAR1e-3: 0.7820\n","output_type":"stream"}],"execution_count":20},{"id":"68e3b204-29e5-4b33-a575-6fa62f0073c3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}