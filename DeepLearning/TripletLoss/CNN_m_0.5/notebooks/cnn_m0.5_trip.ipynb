{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830be2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:40.035290Z",
     "iopub.status.busy": "2025-11-29T18:10:40.035062Z",
     "iopub.status.idle": "2025-11-29T18:10:44.276880Z",
     "shell.execute_reply": "2025-11-29T18:10:44.276098Z"
    },
    "papermill": {
     "duration": 4.248236,
     "end_time": "2025-11-29T18:10:44.278651",
     "exception": false,
     "start_time": "2025-11-29T18:10:40.030415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.2.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "295d0572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:44.286087Z",
     "iopub.status.busy": "2025-11-29T18:10:44.285620Z",
     "iopub.status.idle": "2025-11-29T18:10:54.318177Z",
     "shell.execute_reply": "2025-11-29T18:10:54.317552Z"
    },
    "id": "5a576b15",
    "papermill": {
     "duration": 10.037593,
     "end_time": "2025-11-29T18:10:54.319461",
     "exception": false,
     "start_time": "2025-11-29T18:10:44.281868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import itertools\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "SCORE_DIR = \"/kaggle/input/arc-scores\"\n",
    "if SCORE_DIR not in sys.path:\n",
    "    sys.path.append(SCORE_DIR)\n",
    "import arc_scores\n",
    "HELPER_DIR = \"/kaggle/input/helper-py\"\n",
    "if HELPER_DIR not in sys.path:\n",
    "    sys.path.append(HELPER_DIR)\n",
    "import helper\n",
    "EVULATE_DIR = \"/kaggle/input/evulate\"\n",
    "if EVULATE_DIR not in sys.path:\n",
    "    sys.path.append(EVULATE_DIR)\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da950a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.326526Z",
     "iopub.status.busy": "2025-11-29T18:10:54.326216Z",
     "iopub.status.idle": "2025-11-29T18:10:54.382270Z",
     "shell.execute_reply": "2025-11-29T18:10:54.381522Z"
    },
    "id": "016973f6",
    "outputId": "3dc29e49-1581-458d-e03f-5aebd17db306",
    "papermill": {
     "duration": 0.060847,
     "end_time": "2025-11-29T18:10:54.383476",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.322629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7e281c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.391140Z",
     "iopub.status.busy": "2025-11-29T18:10:54.390592Z",
     "iopub.status.idle": "2025-11-29T18:10:54.396404Z",
     "shell.execute_reply": "2025-11-29T18:10:54.395864Z"
    },
    "id": "6e11101a",
    "papermill": {
     "duration": 0.010934,
     "end_time": "2025-11-29T18:10:54.397473",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.386539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FaceFolderDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root # directory\n",
    "        self.transform = transform\n",
    "        self.samples = []   # (img_path, label)\n",
    "        self.labels = []\n",
    "\n",
    "        persons = sorted(os.listdir(root))\n",
    "        for label, person in enumerate(persons):\n",
    "            self.labels.append(label)\n",
    "            folder = os.path.join(root, person)\n",
    "            if not os.path.isdir(folder):\n",
    "                continue\n",
    "            imgs = glob.glob(os.path.join(folder, \"*\"))\n",
    "            for img_path in imgs:\n",
    "                self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    # allow to use [] to access the index\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc7b2fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.404318Z",
     "iopub.status.busy": "2025-11-29T18:10:54.404091Z",
     "iopub.status.idle": "2025-11-29T18:10:54.412655Z",
     "shell.execute_reply": "2025-11-29T18:10:54.412150Z"
    },
    "id": "49af76fe",
    "papermill": {
     "duration": 0.013252,
     "end_time": "2025-11-29T18:10:54.413641",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.400389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PKSampler(Sampler):\n",
    "    def __init__(self, dataset, P, K, samples_per_class_per_epoch=5):\n",
    "        \"\"\"\n",
    "        dataset: FaceFolderDataset object\n",
    "        P: số classes mỗi batch\n",
    "        K: số samples mỗi class\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.samples_per_class = samples_per_class_per_epoch\n",
    "        self.label2indices = defaultdict(list)\n",
    "\n",
    "        # lấy labels từ samples\n",
    "        for idx, (_, label) in enumerate(dataset.samples):\n",
    "            self.label2indices[label].append(idx)\n",
    "\n",
    "        self.labels = list(self.label2indices.keys())\n",
    "        self.n_classes = len(self.labels)\n",
    "\n",
    "        # Tính số batches\n",
    "        self.batches_per_epoch = (self.n_classes * self.samples_per_class + P - 1) // P\n",
    "\n",
    "        total_images = sum(len(indices) for indices in self.label2indices.values())\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PKSampler Info:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total images: {total_images}\")\n",
    "        print(f\"Total classes: {self.n_classes}\")\n",
    "        print(f\"Avg images/class: {total_images/self.n_classes:.1f}\")\n",
    "        print(f\"Samples per class per epoch: {self.samples_per_class}\")\n",
    "        print(f\"Batches per epoch: {self.batches_per_epoch}\")\n",
    "        print(f\"Total samples per epoch: {self.batches_per_epoch * P * K}\")\n",
    "        print(f\"Coverage: {(self.batches_per_epoch * P * K) / total_images * 100:.1f}%\")\n",
    "        print(f\"Expected time per epoch: ~{self.batches_per_epoch * 0.15:.1f}s (assuming 0.15s/batch)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Mỗi class lặp lại samples_per_class lần\n",
    "        class_pool = []\n",
    "        for _ in range(self.samples_per_class):\n",
    "            shuffled = self.labels.copy()\n",
    "            random.shuffle(shuffled)\n",
    "            class_pool.extend(shuffled)\n",
    "\n",
    "        random.shuffle(class_pool)\n",
    "\n",
    "        for batch_idx in range(self.batches_per_epoch):\n",
    "            start = batch_idx * self.P\n",
    "            batch_labels = class_pool[start:start + self.P]\n",
    "\n",
    "            if len(batch_labels) < self.P:\n",
    "                break\n",
    "\n",
    "            batch = []\n",
    "            for label in batch_labels:\n",
    "                indices = self.label2indices[label]\n",
    "\n",
    "                if len(indices) >= self.K:\n",
    "                    selected = random.sample(indices, k=self.K)\n",
    "                else:\n",
    "                    selected = random.choices(indices, k=self.K)\n",
    "\n",
    "                batch.extend(selected)\n",
    "\n",
    "            yield from batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batches_per_epoch * self.P * self.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808530d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.420518Z",
     "iopub.status.busy": "2025-11-29T18:10:54.419950Z",
     "iopub.status.idle": "2025-11-29T18:10:54.428541Z",
     "shell.execute_reply": "2025-11-29T18:10:54.427835Z"
    },
    "id": "amAQgd0-XkmW",
    "papermill": {
     "duration": 0.013104,
     "end_time": "2025-11-29T18:10:54.429554",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.416450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchHardTripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2, mode='semi_hard'):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.mode = mode\n",
    "\n",
    "    def update_strategy(self, mode):\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, embs, labels):\n",
    "        dist = torch.cdist(embs, embs)\n",
    "\n",
    "        labels = labels.view(-1, 1)\n",
    "        pos_mask = labels.eq(labels.t())\n",
    "        neg_mask = ~pos_mask\n",
    "\n",
    "        eye = torch.eye(len(labels), dtype=torch.bool, device=labels.device)\n",
    "        pos_mask[eye] = False\n",
    "\n",
    "        # Kiểm tra có positive không (mỗi sample cần ít nhất 1 positive)\n",
    "        valid_samples = pos_mask.any(dim=1)\n",
    "\n",
    "        if self.mode == \"semi_hard\":\n",
    "            # Dùng CLOSEST positive (theo paper gốc FaceNet)\n",
    "            pos_dist = dist.clone()\n",
    "            pos_dist[~pos_mask] = 1e9\n",
    "            closest_pos = pos_dist.min(dim=1)[0]  # MIN - positive gần nhất\n",
    "\n",
    "            neg_dist = dist.clone()\n",
    "            neg_dist[~neg_mask] = 1e9\n",
    "\n",
    "            # Semi-hard negative: d(anchor, pos) < d(anchor, neg) < d(anchor, pos) + margin\n",
    "            semi_mask = (neg_dist > closest_pos.unsqueeze(1)) & \\\n",
    "                        (neg_dist < (closest_pos + self.margin).unsqueeze(1))\n",
    "\n",
    "            semi_neg = neg_dist.clone()\n",
    "            semi_neg[~semi_mask] = 1e9\n",
    "            semi_neg = semi_neg.min(dim=1)[0]\n",
    "\n",
    "            # Fallback: nếu không tìm được semi-hard, dùng hardest negative\n",
    "            hardest_neg = neg_dist.min(dim=1)[0]\n",
    "            semi_neg = torch.where(semi_neg >= 1e6, hardest_neg, semi_neg)\n",
    "\n",
    "            loss = torch.relu(closest_pos - semi_neg + self.margin)\n",
    "\n",
    "            # Chỉ tính loss cho samples có positive\n",
    "            if valid_samples.all():\n",
    "                return loss.mean()\n",
    "            else:\n",
    "                return loss[valid_samples].mean() if valid_samples.any() else torch.tensor(0.0, device=embs.device)\n",
    "\n",
    "        # Batch-hard mode: dùng hardest positive và hardest negative\n",
    "        # Hardest positive: positive xa nhất\n",
    "        pos_dist = dist.clone()\n",
    "        pos_dist[~pos_mask] = -1e9\n",
    "        hardest_pos = pos_dist.max(dim=1)[0]\n",
    "\n",
    "        # Hardest negative: negative gần nhất\n",
    "        neg_dist = dist.clone()\n",
    "        neg_dist[~neg_mask] = 1e9\n",
    "        hardest_neg = neg_dist.min(dim=1)[0]\n",
    "\n",
    "        loss = torch.relu(hardest_pos - hardest_neg + self.margin)\n",
    "\n",
    "        # Chỉ tính loss cho samples có positive\n",
    "        if valid_samples.all():\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss[valid_samples].mean() if valid_samples.any() else torch.tensor(0.0, device=embs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be96776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.436316Z",
     "iopub.status.busy": "2025-11-29T18:10:54.436071Z",
     "iopub.status.idle": "2025-11-29T18:10:54.440571Z",
     "shell.execute_reply": "2025-11-29T18:10:54.440067Z"
    },
    "papermill": {
     "duration": 0.009164,
     "end_time": "2025-11-29T18:10:54.441526",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.432362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def pairwise_distance_torch(embeddings, device):\n",
    "#     \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "#     output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "#     Args:\n",
    "#       embeddings: 2-D Tensor of size [number of data, feature dimension].\n",
    "#     Returns:\n",
    "#       pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "#     \"\"\"\n",
    "\n",
    "#     # pairwise distance matrix with precise embeddings\n",
    "#     precise_embeddings = embeddings.to(dtype=torch.float32)\n",
    "\n",
    "#     c1 = torch.pow(precise_embeddings, 2).sum(axis=-1)\n",
    "#     c2 = torch.pow(precise_embeddings.transpose(0, 1), 2).sum(axis=0)\n",
    "#     c3 = precise_embeddings @ precise_embeddings.transpose(0, 1)\n",
    "\n",
    "#     c1 = c1.reshape((c1.shape[0], 1))\n",
    "#     c2 = c2.reshape((1, c2.shape[0]))\n",
    "#     c12 = c1 + c2\n",
    "#     pairwise_distances_squared = c12 - 2.0 * c3\n",
    "\n",
    "#     # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "#     pairwise_distances_squared = torch.max(pairwise_distances_squared, torch.tensor([0.]).to(device))\n",
    "#     # Get the mask where the zero distances are at.\n",
    "#     error_mask = pairwise_distances_squared.clone()\n",
    "#     error_mask[error_mask > 0.0] = 1.\n",
    "#     error_mask[error_mask <= 0.0] = 0.\n",
    "\n",
    "#     pairwise_distances = torch.mul(pairwise_distances_squared, error_mask)\n",
    "\n",
    "#     # Explicitly set diagonals to zero.\n",
    "#     mask_offdiagonals = torch.ones((pairwise_distances.shape[0], pairwise_distances.shape[1])) - torch.diag(torch.ones(pairwise_distances.shape[0]))\n",
    "#     pairwise_distances = torch.mul(pairwise_distances.to(device), mask_offdiagonals.to(device))\n",
    "#     return pairwise_distances\n",
    "\n",
    "# def TripletSemiHardLoss(y_true, y_pred, device, margin=0.5):\n",
    "#     \"\"\"Computes the triplet loss_functions with semi-hard negative mining.\n",
    "#        The loss_functions encourages the positive distances (between a pair of embeddings\n",
    "#        with the same labels) to be smaller than the minimum negative distance\n",
    "#        among which are at least greater than the positive distance plus the\n",
    "#        margin constant (called semi-hard negative) in the mini-batch.\n",
    "#        If no such negative exists, uses the largest negative distance instead.\n",
    "#        See: https://arxiv.org/abs/1503.03832.\n",
    "#        We expect labels `y_true` to be provided as 1-D integer `Tensor` with shape\n",
    "#        [batch_size] of multi-class integer labels. And embeddings `y_pred` must be\n",
    "#        2-D float `Tensor` of l2 normalized embedding vectors.\n",
    "#        Args:\n",
    "#          margin: Float, margin term in the loss_functions definition. Default value is 1.0.\n",
    "#          name: Optional name for the op.\n",
    "#        \"\"\"\n",
    "\n",
    "#     labels, embeddings = y_true, y_pred\n",
    "\n",
    "#     # Reshape label tensor to [batch_size, 1].\n",
    "#     lshape = labels.shape\n",
    "#     labels = torch.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "#     pdist_matrix = pairwise_distance_torch(embeddings, device)\n",
    "\n",
    "#     # Build pairwise binary adjacency matrix.\n",
    "#     adjacency = torch.eq(labels, labels.transpose(0, 1))\n",
    "#     # Invert so we can select negatives only.\n",
    "#     adjacency_not = adjacency.logical_not()\n",
    "\n",
    "#     batch_size = labels.shape[0]\n",
    "\n",
    "#     # Compute the mask.\n",
    "#     pdist_matrix_tile = pdist_matrix.repeat(batch_size, 1)\n",
    "#     adjacency_not_tile = adjacency_not.repeat(batch_size, 1)\n",
    "\n",
    "#     transpose_reshape = pdist_matrix.transpose(0, 1).reshape(-1, 1)\n",
    "#     greater = pdist_matrix_tile > transpose_reshape\n",
    "\n",
    "#     mask = adjacency_not_tile & greater\n",
    "\n",
    "#     # final mask\n",
    "#     mask_step = mask.to(dtype=torch.float32)\n",
    "#     mask_step = mask_step.sum(axis=1)\n",
    "#     mask_step = mask_step > 0.0\n",
    "#     mask_final = mask_step.reshape(batch_size, batch_size)\n",
    "#     mask_final = mask_final.transpose(0, 1)\n",
    "\n",
    "#     adjacency_not = adjacency_not.to(dtype=torch.float32)\n",
    "#     mask = mask.to(dtype=torch.float32)\n",
    "\n",
    "#     # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "#     axis_maximums = torch.max(pdist_matrix_tile, dim=1, keepdim=True)\n",
    "#     masked_minimums = torch.min(torch.mul(pdist_matrix_tile - axis_maximums[0], mask), dim=1, keepdim=True)[0] + axis_maximums[0]\n",
    "#     negatives_outside = masked_minimums.reshape([batch_size, batch_size])\n",
    "#     negatives_outside = negatives_outside.transpose(0, 1)\n",
    "\n",
    "#     # negatives_inside: largest D_an.\n",
    "#     axis_minimums = torch.min(pdist_matrix, dim=1, keepdim=True)\n",
    "#     masked_maximums = torch.max(torch.mul(pdist_matrix - axis_minimums[0], adjacency_not), dim=1, keepdim=True)[0] + axis_minimums[0]\n",
    "#     negatives_inside = masked_maximums.repeat(1, batch_size)\n",
    "\n",
    "#     semi_hard_negatives = torch.where(mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "#     loss_mat = margin + pdist_matrix - semi_hard_negatives\n",
    "\n",
    "#     mask_positives = adjacency.to(dtype=torch.float32) - torch.diag(torch.ones(batch_size)).to(device)\n",
    "#     num_positives = mask_positives.sum()\n",
    "\n",
    "#     triplet_loss = (torch.max(torch.mul(loss_mat, mask_positives), torch.tensor([0.]).to(device))).sum() / num_positives\n",
    "#     triplet_loss = triplet_loss.to(dtype=embeddings.dtype)\n",
    "#     return triplet_loss\n",
    "\n",
    "\n",
    "# class TripletLoss(nn.Module):\n",
    "#     def __init__(self, device):\n",
    "#         super().__init__()\n",
    "#         self.device = device\n",
    "\n",
    "#     def forward(self, input, target, **kwargs):\n",
    "#         return TripletSemiHardLoss(target, input, self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b35429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.448025Z",
     "iopub.status.busy": "2025-11-29T18:10:54.447809Z",
     "iopub.status.idle": "2025-11-29T18:10:54.452121Z",
     "shell.execute_reply": "2025-11-29T18:10:54.451423Z"
    },
    "id": "5MA8YDt5orHb",
    "papermill": {
     "duration": 0.008962,
     "end_time": "2025-11-29T18:10:54.453259",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.444297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29610ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:10:54.460176Z",
     "iopub.status.busy": "2025-11-29T18:10:54.459558Z",
     "iopub.status.idle": "2025-11-29T18:11:52.883030Z",
     "shell.execute_reply": "2025-11-29T18:11:52.882211Z"
    },
    "id": "qW0N8kiFmUKn",
    "outputId": "0553a09c-1213-4898-d4bb-1582cab5af09",
    "papermill": {
     "duration": 58.430629,
     "end_time": "2025-11-29T18:11:52.886745",
     "exception": false,
     "start_time": "2025-11-29T18:10:54.456116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PKSampler Info:\n",
      "============================================================\n",
      "Total images: 1119807\n",
      "Total classes: 5115\n",
      "Avg images/class: 218.9\n",
      "Samples per class per epoch: 10\n",
      "Batches per epoch: 200\n",
      "Total samples per epoch: 204800\n",
      "Coverage: 18.3%\n",
      "Expected time per epoch: ~30.0s (assuming 0.15s/batch)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_path = '/kaggle/input/train-ds/train'\n",
    "val_path = '/kaggle/input/val-ds/val'\n",
    "\n",
    "P, K = 256, 4\n",
    "\n",
    "train_dataset = FaceFolderDataset(train_path, transform=train_transform)\n",
    "val_dataset = FaceFolderDataset(val_path, transform=val_transform)\n",
    "\n",
    "# CÁCH 1: Truyền dataset object\n",
    "train_sampler = PKSampler(\n",
    "    dataset=train_dataset,\n",
    "    P=P,\n",
    "    K=K,\n",
    "    samples_per_class_per_epoch=10  # Mỗi class sample 5 lần/epoch\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=P*K,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=512,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820d2e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:11:52.893472Z",
     "iopub.status.busy": "2025-11-29T18:11:52.893246Z",
     "iopub.status.idle": "2025-11-29T18:11:52.899422Z",
     "shell.execute_reply": "2025-11-29T18:11:52.898852Z"
    },
    "id": "62aeee6a",
    "papermill": {
     "duration": 0.01083,
     "end_time": "2025-11-29T18:11:52.900492",
     "exception": false,
     "start_time": "2025-11-29T18:11:52.889662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, epsilon=0.001, save_path=\"best.pt\"):\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "        self.epsilon = epsilon\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "        self.phase = 1\n",
    "\n",
    "    def step(self, val_acc, model):\n",
    "        if val_acc > self.best_acc + self.epsilon:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'best_tar_far': self.best_acc\n",
    "            }\n",
    "            torch.save(checkpoint, self.save_path)\n",
    "            print(f\"Saved best model: TAR@FAR1e-3={val_acc:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.phase == 1:\n",
    "                    print(\"!!! UPDATE STRATEGY TO HARD MINING !!!\")\n",
    "                    self.phase = 2\n",
    "                    self.counter = 0\n",
    "                    self.patience = 5\n",
    "                elif self.phase == 2:\n",
    "                    self.should_stop = True\n",
    "                    print(\"Early stopping triggered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aecefcf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:11:52.906899Z",
     "iopub.status.busy": "2025-11-29T18:11:52.906692Z",
     "iopub.status.idle": "2025-11-29T18:11:52.912381Z",
     "shell.execute_reply": "2025-11-29T18:11:52.911702Z"
    },
    "papermill": {
     "duration": 0.010152,
     "end_time": "2025-11-29T18:11:52.913441",
     "exception": false,
     "start_time": "2025-11-29T18:11:52.903289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=4096):\n",
    "        super().__init__()\n",
    "\n",
    "        # Phần CNN trích feature map\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 160 -> 151\n",
    "            nn.Conv2d(3, 64, kernel_size=10),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 151 -> 75\n",
    "\n",
    "            # 75 -> 69\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 69 -> 34\n",
    "\n",
    "            # 34 -> 31\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 31 -> 15\n",
    "\n",
    "            # 15 -> 12\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Tính kích thước sau CNN để gán cho FC\n",
    "        # Với input 160x160 -> output 256x12x12\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 12 * 12, embedding_dim),\n",
    "            nn.PReLU(),  # tốt hơn Sigmoid với face embedding\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        # Chuẩn hóa L2 để tính khoảng cách trong không gian metric\n",
    "        return F.normalize(x, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aef39c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:11:52.919869Z",
     "iopub.status.busy": "2025-11-29T18:11:52.919633Z",
     "iopub.status.idle": "2025-11-29T18:11:53.251618Z",
     "shell.execute_reply": "2025-11-29T18:11:53.251041Z"
    },
    "id": "bcfd6b22",
    "papermill": {
     "duration": 0.336694,
     "end_time": "2025-11-29T18:11:53.252921",
     "exception": false,
     "start_time": "2025-11-29T18:11:52.916227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 60\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# model = InceptionResnetV1(pretrained='casia-webface')\n",
    "model = CNN(embedding_dim=512).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4, betas=(0.9, 0.999))\n",
    "criterion = BatchHardTripletLoss(margin=0.5, mode='semi_hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36599d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:11:53.260341Z",
     "iopub.status.busy": "2025-11-29T18:11:53.260104Z",
     "iopub.status.idle": "2025-11-29T18:11:53.281613Z",
     "shell.execute_reply": "2025-11-29T18:11:53.281116Z"
    },
    "id": "645731be",
    "papermill": {
     "duration": 0.026553,
     "end_time": "2025-11-29T18:11:53.282662",
     "exception": false,
     "start_time": "2025-11-29T18:11:53.256109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    tarfar3s = []\n",
    "    tarfar4s = []\n",
    "    accs = []\n",
    "    rocs = []\n",
    "\n",
    "    # early stopping\n",
    "    early = EarlyStopping(patience=3, save_path=\"best.pt\")\n",
    "    is_update = False\n",
    "\n",
    "    # FP16 scaler\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        pbar = tqdm(\n",
    "            enumerate(train_loader),\n",
    "            total=len(train_loader),\n",
    "            desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [LR: {learning_rate:.6f}]\"\n",
    "        )\n",
    "\n",
    "        for step, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ===========================\n",
    "            #       FP16 TRAINING\n",
    "            # ===========================\n",
    "            with autocast(dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "                outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            # Scaler backward\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Clip grad norm (có scale)\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "\n",
    "            # Step optimizer\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        # ==================== EVALUATION ====================\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        embs = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Evaluation không cần autocast\n",
    "            for inputs, targets in tqdm(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                with autocast(dtype=torch.float16):\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = F.normalize(outputs, p=2, dim=1)\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss.append(loss.item())\n",
    "                embs.append(outputs.cpu())\n",
    "                labels.append(targets.cpu())\n",
    "\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        eval_res = evaluate.evaluate(embs, labels, max_per_class=50, n_linspace=1000)\n",
    "\n",
    "        # early stopping\n",
    "        early.step(eval_res[\"tar_far_3\"], model)\n",
    "\n",
    "        # save ckpt + print\n",
    "        helper.save_checkpoint(model, epoch, optimizer, train_loss,\n",
    "                               eval_res[\"tar_far_3\"], eval_res[\"tar_far_4\"])\n",
    "        helper.print_results(optimizer, epoch, NUM_EPOCHS, train_loss, eval_res)\n",
    "\n",
    "        # save scores\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        tarfar3s.append(eval_res[\"tar_far_3\"])\n",
    "        tarfar4s.append(eval_res[\"tar_far_4\"])\n",
    "        accs.append(eval_res[\"accuracy\"])\n",
    "        rocs.append(eval_res[\"roc_auc\"])\n",
    "\n",
    "        # Switch to HARD mining\n",
    "        if early.phase == 2 and not is_update:\n",
    "            is_update = True\n",
    "            criterion.update_strategy(\"hard\")\n",
    "            print(\"Switch loss to HARD mining!\")\n",
    "\n",
    "        if early.should_stop:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nTraining completed! Best TAR@FAR1e-3: {early.best_acc:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses, tarfar3s, tarfar4s, accs, rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9dedf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T18:11:53.289369Z",
     "iopub.status.busy": "2025-11-29T18:11:53.289165Z",
     "iopub.status.idle": "2025-11-30T01:10:05.007447Z",
     "shell.execute_reply": "2025-11-30T01:10:05.006525Z"
    },
    "id": "ec5a73d2",
    "outputId": "311439b0-f5eb-4bef-b942-7da580479107",
    "papermill": {
     "duration": 25092.380924,
     "end_time": "2025-11-30T01:10:05.666527",
     "exception": false,
     "start_time": "2025-11-29T18:11:53.285603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/4248335842.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 1/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [12:17<00:03,  3.71s/it, loss=0.4702]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [07:02<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.0921\n",
      "Saved checkpoint at epoch 1\n",
      "\n",
      "============================================================\n",
      "Epoch 1/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4819\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.7777\n",
      "  - ROC AUC: 0.8563\n",
      "  - TAR@FAR1e-3: 0.0921\n",
      "  - TAR@FAR1e-4: 0.0297\n",
      "  - Threshold: 0.3959\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 2/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [11:01<00:03,  3.32s/it, loss=0.4603]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:03<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.1552\n",
      "Saved checkpoint at epoch 2\n",
      "\n",
      "============================================================\n",
      "Epoch 2/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4634\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8195\n",
      "  - ROC AUC: 0.9006\n",
      "  - TAR@FAR1e-3: 0.1552\n",
      "  - TAR@FAR1e-4: 0.0619\n",
      "  - Threshold: 0.3438\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 3/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [10:33<00:03,  3.18s/it, loss=0.4427]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:11<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.1816\n",
      "Saved checkpoint at epoch 3\n",
      "\n",
      "============================================================\n",
      "Epoch 3/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4507\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8364\n",
      "  - ROC AUC: 0.9161\n",
      "  - TAR@FAR1e-3: 0.1816\n",
      "  - TAR@FAR1e-4: 0.0745\n",
      "  - Threshold: 0.3023\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 4/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:57<00:03,  3.00s/it, loss=0.4410]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:02<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.2199\n",
      "Saved checkpoint at epoch 4\n",
      "\n",
      "============================================================\n",
      "Epoch 4/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4401\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8485\n",
      "  - ROC AUC: 0.9270\n",
      "  - TAR@FAR1e-3: 0.2199\n",
      "  - TAR@FAR1e-4: 0.0924\n",
      "  - Threshold: 0.3021\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 5/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:47<00:02,  2.65s/it, loss=0.4299]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:03<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.2479\n",
      "Saved checkpoint at epoch 5\n",
      "\n",
      "============================================================\n",
      "Epoch 5/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4307\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8558\n",
      "  - ROC AUC: 0.9331\n",
      "  - TAR@FAR1e-3: 0.2479\n",
      "  - TAR@FAR1e-4: 0.1044\n",
      "  - Threshold: 0.2688\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 6/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:57<00:02,  2.70s/it, loss=0.4190]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.2619\n",
      "Saved checkpoint at epoch 6\n",
      "\n",
      "============================================================\n",
      "Epoch 6/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4227\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8636\n",
      "  - ROC AUC: 0.9386\n",
      "  - TAR@FAR1e-3: 0.2619\n",
      "  - TAR@FAR1e-4: 0.1211\n",
      "  - Threshold: 0.2863\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 7/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:12<00:02,  2.78s/it, loss=0.4179]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3008\n",
      "Saved checkpoint at epoch 7\n",
      "\n",
      "============================================================\n",
      "Epoch 7/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4155\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8666\n",
      "  - ROC AUC: 0.9412\n",
      "  - TAR@FAR1e-3: 0.3008\n",
      "  - TAR@FAR1e-4: 0.1392\n",
      "  - Threshold: 0.2779\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 8/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:11<00:02,  2.77s/it, loss=0.3982]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:28<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3063\n",
      "Saved checkpoint at epoch 8\n",
      "\n",
      "============================================================\n",
      "Epoch 8/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4087\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8685\n",
      "  - ROC AUC: 0.9420\n",
      "  - TAR@FAR1e-3: 0.3063\n",
      "  - TAR@FAR1e-4: 0.1481\n",
      "  - Threshold: 0.2816\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 9/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:00<00:02,  2.71s/it, loss=0.3940]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:39<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3335\n",
      "Saved checkpoint at epoch 9\n",
      "\n",
      "============================================================\n",
      "Epoch 9/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.4029\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8762\n",
      "  - ROC AUC: 0.9488\n",
      "  - TAR@FAR1e-3: 0.3335\n",
      "  - TAR@FAR1e-4: 0.1820\n",
      "  - Threshold: 0.2728\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 10/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:16<00:02,  2.79s/it, loss=0.3984]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:30<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3451\n",
      "Saved checkpoint at epoch 10\n",
      "\n",
      "============================================================\n",
      "Epoch 10/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3967\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8809\n",
      "  - ROC AUC: 0.9507\n",
      "  - TAR@FAR1e-3: 0.3451\n",
      "  - TAR@FAR1e-4: 0.1704\n",
      "  - Threshold: 0.2610\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 11/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [09:04<00:02,  2.74s/it, loss=0.3980]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:59<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 11\n",
      "\n",
      "============================================================\n",
      "Epoch 11/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3914\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8796\n",
      "  - ROC AUC: 0.9490\n",
      "  - TAR@FAR1e-3: 0.3348\n",
      "  - TAR@FAR1e-4: 0.1525\n",
      "  - Threshold: 0.2707\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 12/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:21<00:02,  2.52s/it, loss=0.3797]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:32<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3585\n",
      "Saved checkpoint at epoch 12\n",
      "\n",
      "============================================================\n",
      "Epoch 12/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3872\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8849\n",
      "  - ROC AUC: 0.9537\n",
      "  - TAR@FAR1e-3: 0.3585\n",
      "  - TAR@FAR1e-4: 0.1910\n",
      "  - Threshold: 0.2595\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 13/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:09<00:02,  2.46s/it, loss=0.3903]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:57<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3667\n",
      "Saved checkpoint at epoch 13\n",
      "\n",
      "============================================================\n",
      "Epoch 13/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3823\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8864\n",
      "  - ROC AUC: 0.9538\n",
      "  - TAR@FAR1e-3: 0.3667\n",
      "  - TAR@FAR1e-4: 0.2003\n",
      "  - Threshold: 0.2628\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 14/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:01<00:02,  2.42s/it, loss=0.3805]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3926\n",
      "Saved checkpoint at epoch 14\n",
      "\n",
      "============================================================\n",
      "Epoch 14/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3784\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8889\n",
      "  - ROC AUC: 0.9558\n",
      "  - TAR@FAR1e-3: 0.3926\n",
      "  - TAR@FAR1e-4: 0.2119\n",
      "  - Threshold: 0.2550\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 15/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:39<00:02,  2.31s/it, loss=0.3790]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:28<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.3968\n",
      "Saved checkpoint at epoch 15\n",
      "\n",
      "============================================================\n",
      "Epoch 15/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3748\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8927\n",
      "  - ROC AUC: 0.9587\n",
      "  - TAR@FAR1e-3: 0.3968\n",
      "  - TAR@FAR1e-4: 0.2293\n",
      "  - Threshold: 0.2609\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 16/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:32<00:02,  2.27s/it, loss=0.3749]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:35<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4060\n",
      "Saved checkpoint at epoch 16\n",
      "\n",
      "============================================================\n",
      "Epoch 16/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3705\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8947\n",
      "  - ROC AUC: 0.9600\n",
      "  - TAR@FAR1e-3: 0.4060\n",
      "  - TAR@FAR1e-4: 0.2302\n",
      "  - Threshold: 0.2529\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 17/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:28<00:02,  2.26s/it, loss=0.3777]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:32<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4201\n",
      "Saved checkpoint at epoch 17\n",
      "\n",
      "============================================================\n",
      "Epoch 17/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3673\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8960\n",
      "  - ROC AUC: 0.9606\n",
      "  - TAR@FAR1e-3: 0.4201\n",
      "  - TAR@FAR1e-4: 0.2251\n",
      "  - Threshold: 0.2594\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 18/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:27<00:02,  2.25s/it, loss=0.3534]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:29<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 18\n",
      "\n",
      "============================================================\n",
      "Epoch 18/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3632\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8964\n",
      "  - ROC AUC: 0.9600\n",
      "  - TAR@FAR1e-3: 0.4085\n",
      "  - TAR@FAR1e-4: 0.2140\n",
      "  - Threshold: 0.2532\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 19/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:22<00:02,  2.22s/it, loss=0.3601]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:32<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4285\n",
      "Saved checkpoint at epoch 19\n",
      "\n",
      "============================================================\n",
      "Epoch 19/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3613\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8951\n",
      "  - ROC AUC: 0.9593\n",
      "  - TAR@FAR1e-3: 0.4285\n",
      "  - TAR@FAR1e-4: 0.2454\n",
      "  - Threshold: 0.2429\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 20/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [08:16<00:02,  2.49s/it, loss=0.3616]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:34<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4383\n",
      "Saved checkpoint at epoch 20\n",
      "\n",
      "============================================================\n",
      "Epoch 20/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3574\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8989\n",
      "  - ROC AUC: 0.9622\n",
      "  - TAR@FAR1e-3: 0.4383\n",
      "  - TAR@FAR1e-4: 0.2587\n",
      "  - Threshold: 0.2610\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 21/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:36<00:02,  2.29s/it, loss=0.3533]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:35<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4467\n",
      "Saved checkpoint at epoch 21\n",
      "\n",
      "============================================================\n",
      "Epoch 21/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3546\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9005\n",
      "  - ROC AUC: 0.9628\n",
      "  - TAR@FAR1e-3: 0.4467\n",
      "  - TAR@FAR1e-4: 0.2568\n",
      "  - Threshold: 0.2554\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 22/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:12<00:02,  2.17s/it, loss=0.3464]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 22\n",
      "\n",
      "============================================================\n",
      "Epoch 22/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3525\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9000\n",
      "  - ROC AUC: 0.9623\n",
      "  - TAR@FAR1e-3: 0.4387\n",
      "  - TAR@FAR1e-4: 0.2547\n",
      "  - Threshold: 0.2441\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 23/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:21<00:02,  2.22s/it, loss=0.3556]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:05<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4522\n",
      "Saved checkpoint at epoch 23\n",
      "\n",
      "============================================================\n",
      "Epoch 23/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3503\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9024\n",
      "  - ROC AUC: 0.9635\n",
      "  - TAR@FAR1e-3: 0.4522\n",
      "  - TAR@FAR1e-4: 0.2537\n",
      "  - Threshold: 0.2447\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 24/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:13<00:02,  2.18s/it, loss=0.3391]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:50<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4547\n",
      "Saved checkpoint at epoch 24\n",
      "\n",
      "============================================================\n",
      "Epoch 24/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3481\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9002\n",
      "  - ROC AUC: 0.9623\n",
      "  - TAR@FAR1e-3: 0.4547\n",
      "  - TAR@FAR1e-4: 0.2714\n",
      "  - Threshold: 0.2475\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 25/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:14<00:02,  2.18s/it, loss=0.3530]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:28<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4635\n",
      "Saved checkpoint at epoch 25\n",
      "\n",
      "============================================================\n",
      "Epoch 25/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3455\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9045\n",
      "  - ROC AUC: 0.9645\n",
      "  - TAR@FAR1e-3: 0.4635\n",
      "  - TAR@FAR1e-4: 0.2855\n",
      "  - Threshold: 0.2464\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 26/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:14<00:02,  2.19s/it, loss=0.3403]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:30<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 26\n",
      "\n",
      "============================================================\n",
      "Epoch 26/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3429\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9042\n",
      "  - ROC AUC: 0.9642\n",
      "  - TAR@FAR1e-3: 0.4585\n",
      "  - TAR@FAR1e-4: 0.2661\n",
      "  - Threshold: 0.2557\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 27/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:26<00:02,  2.25s/it, loss=0.3487]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:26<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: TAR@FAR1e-3=0.4748\n",
      "Saved checkpoint at epoch 27\n",
      "\n",
      "============================================================\n",
      "Epoch 27/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3409\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9058\n",
      "  - ROC AUC: 0.9658\n",
      "  - TAR@FAR1e-3: 0.4748\n",
      "  - TAR@FAR1e-4: 0.2871\n",
      "  - Threshold: 0.2502\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 28/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:13<00:02,  2.18s/it, loss=0.3327]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:25<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 28\n",
      "\n",
      "============================================================\n",
      "Epoch 28/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3396\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9054\n",
      "  - ROC AUC: 0.9650\n",
      "  - TAR@FAR1e-3: 0.4753\n",
      "  - TAR@FAR1e-4: 0.2829\n",
      "  - Threshold: 0.2583\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 29/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:35<00:02,  2.29s/it, loss=0.3319]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [03:17<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 29\n",
      "\n",
      "============================================================\n",
      "Epoch 29/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3379\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9050\n",
      "  - ROC AUC: 0.9651\n",
      "  - TAR@FAR1e-3: 0.4686\n",
      "  - TAR@FAR1e-4: 0.2807\n",
      "  - Threshold: 0.2566\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 30/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:04<00:02,  2.13s/it, loss=0.3472]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:24<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! UPDATE STRATEGY TO HARD MINING !!!\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "============================================================\n",
      "Epoch 30/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.3356\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.9050\n",
      "  - ROC AUC: 0.9645\n",
      "  - TAR@FAR1e-3: 0.4743\n",
      "  - TAR@FAR1e-4: 0.2833\n",
      "  - Threshold: 0.2522\n",
      "============================================================\n",
      "\n",
      "Switch loss to HARD mining!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 31/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:04<00:02,  2.13s/it, loss=0.5012]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:58<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 31\n",
      "\n",
      "============================================================\n",
      "Epoch 31/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.5096\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8112\n",
      "  - ROC AUC: 0.8941\n",
      "  - TAR@FAR1e-3: 0.1508\n",
      "  - TAR@FAR1e-4: 0.0600\n",
      "  - Threshold: 1.0000\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 32/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:04<00:02,  2.13s/it, loss=0.5008]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:25<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 32\n",
      "\n",
      "============================================================\n",
      "Epoch 32/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.5010\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8028\n",
      "  - ROC AUC: 0.8860\n",
      "  - TAR@FAR1e-3: 0.1290\n",
      "  - TAR@FAR1e-4: 0.0522\n",
      "  - Threshold: 1.0000\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 33/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:06<00:02,  2.14s/it, loss=0.5007]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:48<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 33\n",
      "\n",
      "============================================================\n",
      "Epoch 33/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.5008\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8114\n",
      "  - ROC AUC: 0.8949\n",
      "  - TAR@FAR1e-3: 0.1360\n",
      "  - TAR@FAR1e-4: 0.0507\n",
      "  - Threshold: 1.0000\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 34/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:08<00:02,  2.15s/it, loss=0.5007]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:35<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at epoch 34\n",
      "\n",
      "============================================================\n",
      "Epoch 34/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.5007\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8190\n",
      "  - ROC AUC: 0.9020\n",
      "  - TAR@FAR1e-3: 0.1436\n",
      "  - TAR@FAR1e-4: 0.0581\n",
      "  - Threshold: 1.0000\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60 [LR: 0.000100]:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "Epoch 35/60 [LR: 0.000100]: 100%|█████████▉| 199/200 [07:13<00:02,  2.18s/it, loss=0.5007]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]/tmp/ipykernel_20/4248335842.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "100%|██████████| 225/225 [02:28<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered!\n",
      "Saved checkpoint at epoch 35\n",
      "\n",
      "============================================================\n",
      "Epoch 35/60\n",
      "Learning Rate: Backbone=0.000100\n",
      "Train Loss: 0.5007\n",
      "Eval Metrics:\n",
      "  - Accuracy: 0.8277\n",
      "  - ROC AUC: 0.9102\n",
      "  - TAR@FAR1e-3: 0.1528\n",
      "  - TAR@FAR1e-4: 0.0623\n",
      "  - Threshold: 1.0000\n",
      "============================================================\n",
      "\n",
      "\n",
      "Training completed! Best TAR@FAR1e-3: 0.4748\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, tarfar3s, tarfar4s, accs, rocs = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cbcb1",
   "metadata": {
    "papermill": {
     "duration": 0.853556,
     "end_time": "2025-11-30T01:10:07.454700",
     "exception": false,
     "start_time": "2025-11-30T01:10:06.601144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 442595,
     "sourceId": 1003630,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8770864,
     "sourceId": 13779592,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8827871,
     "sourceId": 13857610,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808355,
     "sourceId": 13857621,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8808735,
     "sourceId": 13858477,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867027,
     "sourceId": 13915972,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867060,
     "sourceId": 13916389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8867030,
     "sourceId": 13916391,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25175.093809,
   "end_time": "2025-11-30T01:10:11.628400",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T18:10:36.534591",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
